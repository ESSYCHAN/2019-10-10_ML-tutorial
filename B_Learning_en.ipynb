{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification\n",
    "\n",
    "In this tutorial we will study in more detail how to build a simple network using pytorch : [LeNet](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf) by Yann LeCun.\n",
    "The code in this tutorial is based on a [example](https://github.com/pytorch/examples/blob/master/mnist/main.py) written in `pytorch`.\n",
    "\n",
    "This network is a convolutional network that has the goal of classifiying digits.\n",
    "\n",
    "This [tutorial](https://www.superdatascience.com/blogs/the-ultimate-guide-to-convolutional-neural-networks-cnn) will allow you to go into more detail in the explanation of this network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "torch.manual_seed(1)\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 1 : definition of the train image and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to start by defining the images we will be working on.\n",
    "Here, we will work on the MNIST dataset, containing images of handwritten numbers.\n",
    "\n",
    "![MNIST](https://knowm.org/wp-content/uploads/Screen-Shot-2015-08-14-at-2.44.57-PM.png)\n",
    "\n",
    "The purpose of the network will be to determine what number is written on the image. To do this, he will have to learn to correctly classify the images with a training dataset. He will then be able to test his learning with a second *validation* dataset.\n",
    "\n",
    "(These two dataset must be different.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of the training batch\n",
    "train_batch_size = 64\n",
    "# size of the test batch\n",
    "test_batch_size = 1000\n",
    "\n",
    "# data transformation\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "\n",
    "# dataset import\n",
    "dataset = datasets.MNIST('images', download=False, transform=transform)\n",
    "\n",
    "# number of images for training (80% of total data)\n",
    "nb_train = int(0.8*len(dataset))\n",
    "# number of images for the test (the rest of the data)\n",
    "nb_test  = len(dataset)-nb_train\n",
    "\n",
    "# separation of data into two datasets\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [nb_train, nb_test])\n",
    "\n",
    "\n",
    "# Data loading\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=train_batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=test_batch_size,  shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The training set contains {} images, in {} batches of {} images\".format(len(train_loader.dataset),\n",
    "                                                                                      len(train_loader),\n",
    "                                                                                      train_batch_size))\n",
    "print(\"The test set contains {} images, in {} batches of {} images\".format(len(test_loader.dataset),\n",
    "                                                                               len(test_loader),\n",
    "                                                                               test_batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 2 : Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1) # convolution 1\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1) # convolution 2\n",
    "        self.fc1 = nn.Linear(4*4*50, 500) # fully connected 1\n",
    "        self.fc2 = nn.Linear(500, 10) # fully connected 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extraction of characteristics 1\n",
    "        x = F.relu(self.conv1(x)) # activation\n",
    "        x = F.max_pool2d(x, 2, 2) # pooling\n",
    "        \n",
    "        # Extraction of characteristics 2\n",
    "        x = F.relu(self.conv2(x)) # activation\n",
    "        x = F.max_pool2d(x, 2, 2) # pooling\n",
    "        x = x.view(-1, 4*4*50) # flattening\n",
    "        \n",
    "        # Classification\n",
    "        x = F.relu(self.fc1(x)) # activation\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the LeNet network consists of two main steps:\n",
    "- the extraction of the image characteristics\n",
    "- the classification of this image according to its characteristics\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/3712/1*7K4ZTTfZb-hbjoADbisHAg.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### extraction of the image characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to extract its characteristics the image will be modified in a series of steps: \n",
    "\n",
    "- a **convolution** (see [Conv2d](https://pytorch.org/docs/stable/nn.html#conv2d), [image parameters](https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md))\n",
    "     - a convolution is a function derived from two functions given by integration that expresses how the shape of one is modified by the other\n",
    "     - the image is convoluted by characteristic detectors (called kernel)\n",
    "     - Attention the entry each convolution layer must be the same size as the exit of the previous convolution layer\n",
    "<img src=\"https://stanford.edu/~shervine/images/convolution-layer-a.png\" width=\"600\"/>\n",
    "<img src=\"https://sds-platform-private.s3-us-east-2.amazonaws.com/uploads/35_blog_image_11.png\" width=\"600\"/>\n",
    "\n",
    "- an **activation function** : Linear Rectification Unit function (see [ReLu()](https://pytorch.org/docs/stable/nn.html#relu))\n",
    "    - to keep only the positive values in the characteristic cards generated by the convolution\n",
    "    - ReLU(x)=max(0,x) <img src=\"https://pytorch.org/docs/stable/_images/ReLU.png\" width=\"400\"/>\n",
    "\n",
    "\n",
    "\n",
    "- a **Pooling** : Max Pooling (see [MaxPool2d](https://pytorch.org/docs/stable/nn.html#maxpool2d))\n",
    "    - to keep only the maximum values in an area\n",
    "    - reduces the characteristic map\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/e/e9/Max_pooling.png\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = 0\n",
    "first_featuremap = 0\n",
    "second_featuremap = 0\n",
    "\n",
    "from Model_show import Plot_model\n",
    "Plot_model(dataset, model.to('cpu'), trial, first_featuremap, second_featuremap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **fully connected** - Linear (see [Linear](https://pytorch.org/docs/stable/nn.html#linear))\n",
    "    - a network where all neurons of the output layer are connected to all neurons from the input layer\n",
    "    - Applies a linear transformation to input data\n",
    "<img src=\"https://jdlm.info/assets/driverless/27-fully-connected.png\" width=\"900\"/>     \n",
    "\n",
    "- log_softmax (see [log_softmax](https://pytorch.org/docs/stable/nn.functional.html#log-softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 3 : Network Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- definition **Function loss** + find the right one!  [wiki](https://en.wikipedia.org/wiki/Convolutional_neural_network)\n",
    "\n",
    "    The loss layer specifies how the network drive penalizes the difference between the expected and actual signal. It is normally the last layer in the network.\n",
    "\n",
    "    Various loss functions adapted to different tasks can be used there [loss-functions](https://pytorch.org/docs/stable/nn.functional.html#loss-functions) :\n",
    "    - The \"Softmax\" loss is used to predict only one of K mutually exclusive classes.\n",
    "    - The sigmoid cross entropy loss is used to predict K values of independent probability in [0.1].\n",
    "    - The Euclidean loss is used to regress to real values in [-inf ,inf].\n",
    "\n",
    "The negative log likelihood loss -> allows to maximize the error when the right label has a low probability and to decrease it when the right label has a high probability!\n",
    "\n",
    "- Backpropagation\n",
    "    - the computation error spreads to the first layer of the network\n",
    "<img src=\"https://d3i71xaburhd42.cloudfront.net/db39fd79bb591b04d33207992f6ccde03cabd861/7-Figure1-1.png\" width=\"400\"/>\n",
    "\n",
    "    - To perform backpropagation in pytorch, the following steps are necessary for each iteration of the loop:\n",
    "\n",
    "        1. **optimize.zero_grad()** : resets the gradients of each parameter to zero.\n",
    "        2. **loss.backward()** : calculates the gradiants for each variable by backpropagation according to the loss, and stores them in the Variable object\n",
    "        3. **optimize.step()** : Modifies each model parameter (network weight) to minimize loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, log_interval):\n",
    "    model.train() # put in training mode\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad() # important ! resets the gradients to 0\n",
    "        output = model(data) # calculates the prediction\n",
    "        loss = F.nll_loss(output, target) # calculates the error: The negative log likelihood loss.\n",
    "        loss.backward() # drifts the graph\n",
    "        optimizer.step() # performs an optimization step\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we tell the model if we want to work on a GPU or a CPU\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = Net().to(device)\n",
    "\n",
    "# the optimizer allows to calculate the network weights\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "train(model, device, train_loader, optimizer, 0, 749)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 3 : Network Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset), 100. * correct/len(test_loader.dataset)))\n",
    "    return(100. * correct/len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we're going to test the model for 15 trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_test = 15\n",
    "dict_test = dict(iter(test_loader))\n",
    "inps = list(dict_test.keys())\n",
    "inp = inps[0][:N_test]\n",
    "targ = dict_test[inps[0]][:N_test]\n",
    "\n",
    "i = inp.view(inp.shape[0], 1, inp.shape[2], inp.shape[3])\n",
    "\n",
    "import torchvision.utils as vutils\n",
    "grid_images = vutils.make_grid(i, nrow=N_test)\n",
    "images = np.transpose(grid_images, (1,2,0))\n",
    "\n",
    "plt.figure(figsize=(5*N_test, 5))\n",
    "plt.imshow(images)\n",
    "plt.xticks([]) ; plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "out = model(i.to(device))\n",
    "pred = out.argmax(dim=1, keepdim=True)\n",
    "print('target :', targ,\n",
    "      '\\nprediction :', pred.to('cpu').view(-1),\n",
    "      '\\nnumber of good predictions :', pred.eq(targ.to(device).view_as(pred)).sum().item(),\n",
    "      '\\ntotal number predictions :', N_test)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 4 : evolution of accuracy at the heart of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we train the model on several epochs by testing it for each epoch in order to see its evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we tell the model if we want to work on a GPU or a CPU\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = Net().to(device)\n",
    "# the optimizer allows to calculate the network weights\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "# to reset the weights in the model to zero!\n",
    "#########################################################\n",
    "def weight_reset(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()\n",
    "\n",
    "model.apply(weight_reset)\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "log_interval = 749\n",
    "\n",
    "list_accuracy = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch, log_interval)\n",
    "    accuracy = test(model, device, test_loader)\n",
    "    list_accuracy.append(accuracy)\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(),\"model/mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,len(list_accuracy)+1), list_accuracy, 'k')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.axis([0.9,len(list_accuracy)+0.1,90,100]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = 0\n",
    "first_featuremap = 0\n",
    "second_featuremap = 0\n",
    "\n",
    "Plot_model(dataset, model.to('cpu'), trial, first_featuremap, second_featuremap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the Kernels of the two convolutions of the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kernels used by the model are stored in:\n",
    "- `model.conv1.weight` for the first convolution\n",
    "- `model.conv2.weight` for the second convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model_show import transform_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All kernels of convolution 1 :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4,5, figsize=(15,15))\n",
    "for num_w in range(model.conv1.weight.shape[0]) :\n",
    "    w = model.conv1.weight[num_w].to('cpu')\n",
    "    \n",
    "    a, b = num_w//5, num_w%5\n",
    "    ax[a][b].imshow(transform_img(w))\n",
    "    ax[a][b].set_title(num_w+1)\n",
    "    ax[a][b].set_xticks([]) ; ax[a][b].set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All kernels of convolution 2 for the characteristic cards of the first kernel of convolution 1 :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(10,5, figsize=(15,15))\n",
    "for num_w in range(model.conv2.weight.shape[0]) :\n",
    "    w = model.conv2.weight[num_w][0].view(1,5,5).to('cpu')\n",
    "    \n",
    "    a, b = num_w//5, num_w%5\n",
    "    ax[a][b].imshow(transform_img(w))\n",
    "    ax[a][b].set_title(num_w+1)\n",
    "    ax[a][b].set_xticks([]) ; ax[a][b].set_yticks([])\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
