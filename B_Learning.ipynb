{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification d'image\n",
    "\n",
    "https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "\n",
    "http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf\n",
    "\n",
    "https://www.superdatascience.com/blogs/the-ultimate-guide-to-convolutional-neural-networks-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## étape 1 : définition des image train et eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set contains 48000 images, in 750 batches\n",
      "The test set contains 12000 images, in 12 batches\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "train_batch_size = 64\n",
    "test_batch_size = 1000\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "\n",
    "# random_split\n",
    "dataset = datasets.MNIST('images', train=True, download=True, transform=transform)\n",
    "\n",
    "nb_train = int(0.8*len(dataset))\n",
    "nb_test  = len(dataset)-nb_train\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [nb_train, nb_test])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=train_batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=test_batch_size,  shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "print(\"The train set contains {} images, in {} batches\".format(len(train_loader.dataset), len(train_loader)))\n",
    "print(\"The test set contains {} images, in {} batches\".format(len(test_loader.dataset), len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## étape 2 : Réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "le réseau LeNet définit ici est composé de plusieurs briques :\n",
    "\n",
    "- Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode) : voir [Conv2d](https://pytorch.org/docs/stable/nn.html#conv2d)\n",
    "     - Applique une convolution 2D sur un signal d'entrée composé de plusieurs plans d'entrée.\n",
    "     - la convolution est une fonction dérivée de deux fonctions données par intégration qui exprime comment la forme de l'une est modifiée par l'autre\n",
    "![Conv2d](https://github.com/vdumoulin/conv_arithmetic/blob/master/gif/no_padding_no_strides.gif?raw=true)\n",
    "![Conv](https://sds-platform-private.s3-us-east-2.amazonaws.com/uploads/35_blog_image_11.png)\n",
    "\n",
    "\n",
    "- ReLU() : voir [ReLu](https://pytorch.org/docs/stable/nn.html#relu)\n",
    "    - Applique la fonction d'Unité de Rectification Linéaire : ReLU(x)=max(0,x)    \n",
    "![ReLu](https://pytorch.org/docs/stable/_images/ReLU.png)\n",
    "\n",
    "\n",
    "\n",
    "- MaxPool2d(kernel_size, stride, padding, dilation, return_indices, ceil_mode) : voir [MaxPool2d](https://pytorch.org/docs/stable/nn.html#maxpool2d)\n",
    "    - Applique un Max Pooling 2D sur un signal d'entrée composé de plusieurs plans d'entrée.\n",
    "    - permet d'évité un surapprentissage\n",
    "![max_pooling](https://upload.wikimedia.org/wikipedia/commons/e/e9/Max_pooling.png)\n",
    "\n",
    "\n",
    "\n",
    "- Linear(in_features, out_features, bias) : voir [Linear](https://pytorch.org/docs/stable/nn.html#linear)\n",
    "    - Applique une transformation linéaire aux données entrantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## étape 3 : Entrainement du Réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target) # The negative log likelihood loss.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- définition fonction loss + trouver la bonne ! [wiki](https://fr.wikipedia.org/wiki/R%C3%A9seau_neuronal_convolutif)\n",
    "\n",
    "    La couche de perte spécifie comment l'entrainement du réseau pénalise l'écart entre le signal prévu et réel. Elle est normalement la dernière couche dans le réseau.\n",
    "\n",
    "    Diverses fonctions de perte adaptées à différentes tâches peuvent y être utilisées [loss-functions](https://pytorch.org/docs/stable/nn.functional.html#loss-functions) :\n",
    "    - La perte « Softmax »est utilisée pour prédire une seule classe parmi K classes mutuellement exclusives.\n",
    "    - La perte par entropie croisée sigmoïde est utilisée pour prédire K valeurs de probabilité indépendante dans [0,1].\n",
    "    - La perte euclidienne est utilisée pour régresser vers des valeurs réelles dans [-inf ,inf].\n",
    "\n",
    "The negative log likelihood loss -> permet de maximiser l'erreur quand le bon label a une proba faible et de la diminuer quand bon label a proba élevé !\n",
    "\n",
    "- backpropagation\n",
    "    - l'erreur calculer se propage dans les première couche du réseau\n",
    "\n",
    "![backpropagation](https://d3i71xaburhd42.cloudfront.net/db39fd79bb591b04d33207992f6ccde03cabd861/7-Figure1-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## étape 3 : Test du Réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    \n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct/len(test_loader.dataset)))\n",
    "    return(100. * correct/len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/48000 (0%)]\tLoss: 2.288539\n",
      "Train Epoch: 1 [640/48000 (1%)]\tLoss: 2.227906\n",
      "Train Epoch: 1 [1280/48000 (3%)]\tLoss: 2.151350\n",
      "Train Epoch: 1 [1920/48000 (4%)]\tLoss: 1.943182\n",
      "Train Epoch: 1 [2560/48000 (5%)]\tLoss: 1.651280\n",
      "Train Epoch: 1 [3200/48000 (7%)]\tLoss: 1.261056\n",
      "Train Epoch: 1 [3840/48000 (8%)]\tLoss: 0.948923\n",
      "Train Epoch: 1 [4480/48000 (9%)]\tLoss: 0.624222\n",
      "Train Epoch: 1 [5120/48000 (11%)]\tLoss: 0.720307\n",
      "Train Epoch: 1 [5760/48000 (12%)]\tLoss: 0.471365\n",
      "Train Epoch: 1 [6400/48000 (13%)]\tLoss: 0.497487\n",
      "Train Epoch: 1 [7040/48000 (15%)]\tLoss: 0.517062\n",
      "Train Epoch: 1 [7680/48000 (16%)]\tLoss: 0.425597\n",
      "Train Epoch: 1 [8320/48000 (17%)]\tLoss: 0.401933\n",
      "Train Epoch: 1 [8960/48000 (19%)]\tLoss: 0.268521\n",
      "Train Epoch: 1 [9600/48000 (20%)]\tLoss: 0.356394\n",
      "Train Epoch: 1 [10240/48000 (21%)]\tLoss: 0.434971\n",
      "Train Epoch: 1 [10880/48000 (23%)]\tLoss: 0.492551\n",
      "Train Epoch: 1 [11520/48000 (24%)]\tLoss: 0.253212\n",
      "Train Epoch: 1 [12160/48000 (25%)]\tLoss: 0.227505\n",
      "Train Epoch: 1 [12800/48000 (27%)]\tLoss: 0.217618\n",
      "Train Epoch: 1 [13440/48000 (28%)]\tLoss: 0.168717\n",
      "Train Epoch: 1 [14080/48000 (29%)]\tLoss: 0.305230\n",
      "Train Epoch: 1 [14720/48000 (31%)]\tLoss: 0.142230\n",
      "Train Epoch: 1 [15360/48000 (32%)]\tLoss: 0.521355\n",
      "Train Epoch: 1 [16000/48000 (33%)]\tLoss: 0.279969\n",
      "Train Epoch: 1 [16640/48000 (35%)]\tLoss: 0.266983\n",
      "Train Epoch: 1 [17280/48000 (36%)]\tLoss: 0.228961\n",
      "Train Epoch: 1 [17920/48000 (37%)]\tLoss: 0.179522\n",
      "Train Epoch: 1 [18560/48000 (39%)]\tLoss: 0.281049\n",
      "Train Epoch: 1 [19200/48000 (40%)]\tLoss: 0.199141\n",
      "Train Epoch: 1 [19840/48000 (41%)]\tLoss: 0.191804\n",
      "Train Epoch: 1 [20480/48000 (43%)]\tLoss: 0.277111\n",
      "Train Epoch: 1 [21120/48000 (44%)]\tLoss: 0.163882\n",
      "Train Epoch: 1 [21760/48000 (45%)]\tLoss: 0.259607\n",
      "Train Epoch: 1 [22400/48000 (47%)]\tLoss: 0.255945\n",
      "Train Epoch: 1 [23040/48000 (48%)]\tLoss: 0.288060\n",
      "Train Epoch: 1 [23680/48000 (49%)]\tLoss: 0.213295\n",
      "Train Epoch: 1 [24320/48000 (51%)]\tLoss: 0.075398\n",
      "Train Epoch: 1 [24960/48000 (52%)]\tLoss: 0.231087\n",
      "Train Epoch: 1 [25600/48000 (53%)]\tLoss: 0.417461\n",
      "Train Epoch: 1 [26240/48000 (55%)]\tLoss: 0.206568\n",
      "Train Epoch: 1 [26880/48000 (56%)]\tLoss: 0.155000\n",
      "Train Epoch: 1 [27520/48000 (57%)]\tLoss: 0.128576\n",
      "Train Epoch: 1 [28160/48000 (59%)]\tLoss: 0.142951\n",
      "Train Epoch: 1 [28800/48000 (60%)]\tLoss: 0.125486\n",
      "Train Epoch: 1 [29440/48000 (61%)]\tLoss: 0.164763\n",
      "Train Epoch: 1 [30080/48000 (63%)]\tLoss: 0.083588\n",
      "Train Epoch: 1 [30720/48000 (64%)]\tLoss: 0.173232\n",
      "Train Epoch: 1 [31360/48000 (65%)]\tLoss: 0.177115\n",
      "Train Epoch: 1 [32000/48000 (67%)]\tLoss: 0.228016\n",
      "Train Epoch: 1 [32640/48000 (68%)]\tLoss: 0.250120\n",
      "Train Epoch: 1 [33280/48000 (69%)]\tLoss: 0.142547\n",
      "Train Epoch: 1 [33920/48000 (71%)]\tLoss: 0.044506\n",
      "Train Epoch: 1 [34560/48000 (72%)]\tLoss: 0.206819\n",
      "Train Epoch: 1 [35200/48000 (73%)]\tLoss: 0.216478\n",
      "Train Epoch: 1 [35840/48000 (75%)]\tLoss: 0.156309\n",
      "Train Epoch: 1 [36480/48000 (76%)]\tLoss: 0.239480\n",
      "Train Epoch: 1 [37120/48000 (77%)]\tLoss: 0.091329\n",
      "Train Epoch: 1 [37760/48000 (79%)]\tLoss: 0.112824\n",
      "Train Epoch: 1 [38400/48000 (80%)]\tLoss: 0.174698\n",
      "Train Epoch: 1 [39040/48000 (81%)]\tLoss: 0.256247\n",
      "Train Epoch: 1 [39680/48000 (83%)]\tLoss: 0.116511\n",
      "Train Epoch: 1 [40320/48000 (84%)]\tLoss: 0.105941\n",
      "Train Epoch: 1 [40960/48000 (85%)]\tLoss: 0.158914\n",
      "Train Epoch: 1 [41600/48000 (87%)]\tLoss: 0.113569\n",
      "Train Epoch: 1 [42240/48000 (88%)]\tLoss: 0.058748\n",
      "Train Epoch: 1 [42880/48000 (89%)]\tLoss: 0.084954\n",
      "Train Epoch: 1 [43520/48000 (91%)]\tLoss: 0.049640\n",
      "Train Epoch: 1 [44160/48000 (92%)]\tLoss: 0.147094\n",
      "Train Epoch: 1 [44800/48000 (93%)]\tLoss: 0.185562\n",
      "Train Epoch: 1 [45440/48000 (95%)]\tLoss: 0.156644\n",
      "Train Epoch: 1 [46080/48000 (96%)]\tLoss: 0.093494\n",
      "Train Epoch: 1 [46720/48000 (97%)]\tLoss: 0.180138\n",
      "Train Epoch: 1 [47360/48000 (99%)]\tLoss: 0.122191\n",
      "\n",
      "Test set: Average loss: 0.1177, Accuracy: 11571/12000 (96%)\n",
      "\n",
      "Train Epoch: 2 [0/48000 (0%)]\tLoss: 0.260446\n",
      "Train Epoch: 2 [640/48000 (1%)]\tLoss: 0.099079\n",
      "Train Epoch: 2 [1280/48000 (3%)]\tLoss: 0.105038\n",
      "Train Epoch: 2 [1920/48000 (4%)]\tLoss: 0.072023\n",
      "Train Epoch: 2 [2560/48000 (5%)]\tLoss: 0.090892\n",
      "Train Epoch: 2 [3200/48000 (7%)]\tLoss: 0.122440\n",
      "Train Epoch: 2 [3840/48000 (8%)]\tLoss: 0.088117\n",
      "Train Epoch: 2 [4480/48000 (9%)]\tLoss: 0.053098\n",
      "Train Epoch: 2 [5120/48000 (11%)]\tLoss: 0.225099\n",
      "Train Epoch: 2 [5760/48000 (12%)]\tLoss: 0.169618\n",
      "Train Epoch: 2 [6400/48000 (13%)]\tLoss: 0.114775\n",
      "Train Epoch: 2 [7040/48000 (15%)]\tLoss: 0.154049\n",
      "Train Epoch: 2 [7680/48000 (16%)]\tLoss: 0.045787\n",
      "Train Epoch: 2 [8320/48000 (17%)]\tLoss: 0.065242\n",
      "Train Epoch: 2 [8960/48000 (19%)]\tLoss: 0.116023\n",
      "Train Epoch: 2 [9600/48000 (20%)]\tLoss: 0.062720\n",
      "Train Epoch: 2 [10240/48000 (21%)]\tLoss: 0.131326\n",
      "Train Epoch: 2 [10880/48000 (23%)]\tLoss: 0.172355\n",
      "Train Epoch: 2 [11520/48000 (24%)]\tLoss: 0.263885\n",
      "Train Epoch: 2 [12160/48000 (25%)]\tLoss: 0.075572\n",
      "Train Epoch: 2 [12800/48000 (27%)]\tLoss: 0.352550\n",
      "Train Epoch: 2 [13440/48000 (28%)]\tLoss: 0.179416\n",
      "Train Epoch: 2 [14080/48000 (29%)]\tLoss: 0.156745\n",
      "Train Epoch: 2 [14720/48000 (31%)]\tLoss: 0.132141\n",
      "Train Epoch: 2 [15360/48000 (32%)]\tLoss: 0.119731\n",
      "Train Epoch: 2 [16000/48000 (33%)]\tLoss: 0.089613\n",
      "Train Epoch: 2 [16640/48000 (35%)]\tLoss: 0.066390\n",
      "Train Epoch: 2 [17280/48000 (36%)]\tLoss: 0.024629\n",
      "Train Epoch: 2 [17920/48000 (37%)]\tLoss: 0.096569\n",
      "Train Epoch: 2 [18560/48000 (39%)]\tLoss: 0.110397\n",
      "Train Epoch: 2 [19200/48000 (40%)]\tLoss: 0.146518\n",
      "Train Epoch: 2 [19840/48000 (41%)]\tLoss: 0.056344\n",
      "Train Epoch: 2 [20480/48000 (43%)]\tLoss: 0.070146\n",
      "Train Epoch: 2 [21120/48000 (44%)]\tLoss: 0.085885\n",
      "Train Epoch: 2 [21760/48000 (45%)]\tLoss: 0.093601\n",
      "Train Epoch: 2 [22400/48000 (47%)]\tLoss: 0.052112\n",
      "Train Epoch: 2 [23040/48000 (48%)]\tLoss: 0.030572\n",
      "Train Epoch: 2 [23680/48000 (49%)]\tLoss: 0.075530\n",
      "Train Epoch: 2 [24320/48000 (51%)]\tLoss: 0.074294\n",
      "Train Epoch: 2 [24960/48000 (52%)]\tLoss: 0.104267\n",
      "Train Epoch: 2 [25600/48000 (53%)]\tLoss: 0.098567\n",
      "Train Epoch: 2 [26240/48000 (55%)]\tLoss: 0.094245\n",
      "Train Epoch: 2 [26880/48000 (56%)]\tLoss: 0.057673\n",
      "Train Epoch: 2 [27520/48000 (57%)]\tLoss: 0.168690\n",
      "Train Epoch: 2 [28160/48000 (59%)]\tLoss: 0.031270\n",
      "Train Epoch: 2 [28800/48000 (60%)]\tLoss: 0.045499\n",
      "Train Epoch: 2 [29440/48000 (61%)]\tLoss: 0.062972\n",
      "Train Epoch: 2 [30080/48000 (63%)]\tLoss: 0.180377\n",
      "Train Epoch: 2 [30720/48000 (64%)]\tLoss: 0.081577\n",
      "Train Epoch: 2 [31360/48000 (65%)]\tLoss: 0.025389\n",
      "Train Epoch: 2 [32000/48000 (67%)]\tLoss: 0.023630\n",
      "Train Epoch: 2 [32640/48000 (68%)]\tLoss: 0.113398\n",
      "Train Epoch: 2 [33280/48000 (69%)]\tLoss: 0.114942\n",
      "Train Epoch: 2 [33920/48000 (71%)]\tLoss: 0.040423\n",
      "Train Epoch: 2 [34560/48000 (72%)]\tLoss: 0.046759\n",
      "Train Epoch: 2 [35200/48000 (73%)]\tLoss: 0.024505\n",
      "Train Epoch: 2 [35840/48000 (75%)]\tLoss: 0.033023\n",
      "Train Epoch: 2 [36480/48000 (76%)]\tLoss: 0.049717\n",
      "Train Epoch: 2 [37120/48000 (77%)]\tLoss: 0.150165\n",
      "Train Epoch: 2 [37760/48000 (79%)]\tLoss: 0.115330\n",
      "Train Epoch: 2 [38400/48000 (80%)]\tLoss: 0.061460\n",
      "Train Epoch: 2 [39040/48000 (81%)]\tLoss: 0.127253\n",
      "Train Epoch: 2 [39680/48000 (83%)]\tLoss: 0.075690\n",
      "Train Epoch: 2 [40320/48000 (84%)]\tLoss: 0.018457\n",
      "Train Epoch: 2 [40960/48000 (85%)]\tLoss: 0.157146\n",
      "Train Epoch: 2 [41600/48000 (87%)]\tLoss: 0.015465\n",
      "Train Epoch: 2 [42240/48000 (88%)]\tLoss: 0.191498\n",
      "Train Epoch: 2 [42880/48000 (89%)]\tLoss: 0.017264\n",
      "Train Epoch: 2 [43520/48000 (91%)]\tLoss: 0.097995\n",
      "Train Epoch: 2 [44160/48000 (92%)]\tLoss: 0.039163\n",
      "Train Epoch: 2 [44800/48000 (93%)]\tLoss: 0.139486\n",
      "Train Epoch: 2 [45440/48000 (95%)]\tLoss: 0.056596\n",
      "Train Epoch: 2 [46080/48000 (96%)]\tLoss: 0.032395\n",
      "Train Epoch: 2 [46720/48000 (97%)]\tLoss: 0.198683\n",
      "Train Epoch: 2 [47360/48000 (99%)]\tLoss: 0.087784\n",
      "\n",
      "Test set: Average loss: 0.0748, Accuracy: 11720/12000 (98%)\n",
      "\n",
      "Train Epoch: 3 [0/48000 (0%)]\tLoss: 0.084362\n",
      "Train Epoch: 3 [640/48000 (1%)]\tLoss: 0.083564\n",
      "Train Epoch: 3 [1280/48000 (3%)]\tLoss: 0.126614\n",
      "Train Epoch: 3 [1920/48000 (4%)]\tLoss: 0.045694\n",
      "Train Epoch: 3 [2560/48000 (5%)]\tLoss: 0.077018\n",
      "Train Epoch: 3 [3200/48000 (7%)]\tLoss: 0.018340\n",
      "Train Epoch: 3 [3840/48000 (8%)]\tLoss: 0.034622\n",
      "Train Epoch: 3 [4480/48000 (9%)]\tLoss: 0.099157\n",
      "Train Epoch: 3 [5120/48000 (11%)]\tLoss: 0.093412\n",
      "Train Epoch: 3 [5760/48000 (12%)]\tLoss: 0.048941\n",
      "Train Epoch: 3 [6400/48000 (13%)]\tLoss: 0.075013\n",
      "Train Epoch: 3 [7040/48000 (15%)]\tLoss: 0.046548\n",
      "Train Epoch: 3 [7680/48000 (16%)]\tLoss: 0.141904\n",
      "Train Epoch: 3 [8320/48000 (17%)]\tLoss: 0.044868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [8960/48000 (19%)]\tLoss: 0.058604\n",
      "Train Epoch: 3 [9600/48000 (20%)]\tLoss: 0.068653\n",
      "Train Epoch: 3 [10240/48000 (21%)]\tLoss: 0.043099\n",
      "Train Epoch: 3 [10880/48000 (23%)]\tLoss: 0.050769\n",
      "Train Epoch: 3 [11520/48000 (24%)]\tLoss: 0.018408\n",
      "Train Epoch: 3 [12160/48000 (25%)]\tLoss: 0.058554\n",
      "Train Epoch: 3 [12800/48000 (27%)]\tLoss: 0.051829\n",
      "Train Epoch: 3 [13440/48000 (28%)]\tLoss: 0.066157\n",
      "Train Epoch: 3 [14080/48000 (29%)]\tLoss: 0.095401\n",
      "Train Epoch: 3 [14720/48000 (31%)]\tLoss: 0.066974\n",
      "Train Epoch: 3 [15360/48000 (32%)]\tLoss: 0.036926\n",
      "Train Epoch: 3 [16000/48000 (33%)]\tLoss: 0.077091\n",
      "Train Epoch: 3 [16640/48000 (35%)]\tLoss: 0.174669\n",
      "Train Epoch: 3 [17280/48000 (36%)]\tLoss: 0.160589\n",
      "Train Epoch: 3 [17920/48000 (37%)]\tLoss: 0.029211\n",
      "Train Epoch: 3 [18560/48000 (39%)]\tLoss: 0.027080\n",
      "Train Epoch: 3 [19200/48000 (40%)]\tLoss: 0.056739\n",
      "Train Epoch: 3 [19840/48000 (41%)]\tLoss: 0.064221\n",
      "Train Epoch: 3 [20480/48000 (43%)]\tLoss: 0.034795\n",
      "Train Epoch: 3 [21120/48000 (44%)]\tLoss: 0.041305\n",
      "Train Epoch: 3 [21760/48000 (45%)]\tLoss: 0.044505\n",
      "Train Epoch: 3 [22400/48000 (47%)]\tLoss: 0.021542\n",
      "Train Epoch: 3 [23040/48000 (48%)]\tLoss: 0.049786\n",
      "Train Epoch: 3 [23680/48000 (49%)]\tLoss: 0.067579\n",
      "Train Epoch: 3 [24320/48000 (51%)]\tLoss: 0.309051\n",
      "Train Epoch: 3 [24960/48000 (52%)]\tLoss: 0.073575\n",
      "Train Epoch: 3 [25600/48000 (53%)]\tLoss: 0.170211\n",
      "Train Epoch: 3 [26240/48000 (55%)]\tLoss: 0.095557\n",
      "Train Epoch: 3 [26880/48000 (56%)]\tLoss: 0.033624\n",
      "Train Epoch: 3 [27520/48000 (57%)]\tLoss: 0.141376\n",
      "Train Epoch: 3 [28160/48000 (59%)]\tLoss: 0.052539\n",
      "Train Epoch: 3 [28800/48000 (60%)]\tLoss: 0.087758\n",
      "Train Epoch: 3 [29440/48000 (61%)]\tLoss: 0.048527\n",
      "Train Epoch: 3 [30080/48000 (63%)]\tLoss: 0.036936\n",
      "Train Epoch: 3 [30720/48000 (64%)]\tLoss: 0.132214\n",
      "Train Epoch: 3 [31360/48000 (65%)]\tLoss: 0.082189\n",
      "Train Epoch: 3 [32000/48000 (67%)]\tLoss: 0.038725\n",
      "Train Epoch: 3 [32640/48000 (68%)]\tLoss: 0.040507\n",
      "Train Epoch: 3 [33280/48000 (69%)]\tLoss: 0.040024\n",
      "Train Epoch: 3 [33920/48000 (71%)]\tLoss: 0.127885\n",
      "Train Epoch: 3 [34560/48000 (72%)]\tLoss: 0.246151\n",
      "Train Epoch: 3 [35200/48000 (73%)]\tLoss: 0.023112\n",
      "Train Epoch: 3 [35840/48000 (75%)]\tLoss: 0.040846\n",
      "Train Epoch: 3 [36480/48000 (76%)]\tLoss: 0.056743\n",
      "Train Epoch: 3 [37120/48000 (77%)]\tLoss: 0.008897\n",
      "Train Epoch: 3 [37760/48000 (79%)]\tLoss: 0.053011\n",
      "Train Epoch: 3 [38400/48000 (80%)]\tLoss: 0.048587\n",
      "Train Epoch: 3 [39040/48000 (81%)]\tLoss: 0.046992\n",
      "Train Epoch: 3 [39680/48000 (83%)]\tLoss: 0.014370\n",
      "Train Epoch: 3 [40320/48000 (84%)]\tLoss: 0.051294\n",
      "Train Epoch: 3 [40960/48000 (85%)]\tLoss: 0.053055\n",
      "Train Epoch: 3 [41600/48000 (87%)]\tLoss: 0.009789\n",
      "Train Epoch: 3 [42240/48000 (88%)]\tLoss: 0.027415\n",
      "Train Epoch: 3 [42880/48000 (89%)]\tLoss: 0.064299\n",
      "Train Epoch: 3 [43520/48000 (91%)]\tLoss: 0.037129\n",
      "Train Epoch: 3 [44160/48000 (92%)]\tLoss: 0.026146\n",
      "Train Epoch: 3 [44800/48000 (93%)]\tLoss: 0.075813\n",
      "Train Epoch: 3 [45440/48000 (95%)]\tLoss: 0.038007\n",
      "Train Epoch: 3 [46080/48000 (96%)]\tLoss: 0.069056\n",
      "Train Epoch: 3 [46720/48000 (97%)]\tLoss: 0.134699\n",
      "Train Epoch: 3 [47360/48000 (99%)]\tLoss: 0.030721\n",
      "\n",
      "Test set: Average loss: 0.0679, Accuracy: 11739/12000 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/48000 (0%)]\tLoss: 0.021778\n",
      "Train Epoch: 4 [640/48000 (1%)]\tLoss: 0.045464\n",
      "Train Epoch: 4 [1280/48000 (3%)]\tLoss: 0.019106\n",
      "Train Epoch: 4 [1920/48000 (4%)]\tLoss: 0.039385\n",
      "Train Epoch: 4 [2560/48000 (5%)]\tLoss: 0.053813\n",
      "Train Epoch: 4 [3200/48000 (7%)]\tLoss: 0.075423\n",
      "Train Epoch: 4 [3840/48000 (8%)]\tLoss: 0.059100\n",
      "Train Epoch: 4 [4480/48000 (9%)]\tLoss: 0.073043\n",
      "Train Epoch: 4 [5120/48000 (11%)]\tLoss: 0.192041\n",
      "Train Epoch: 4 [5760/48000 (12%)]\tLoss: 0.017721\n",
      "Train Epoch: 4 [6400/48000 (13%)]\tLoss: 0.045307\n",
      "Train Epoch: 4 [7040/48000 (15%)]\tLoss: 0.100796\n",
      "Train Epoch: 4 [7680/48000 (16%)]\tLoss: 0.048789\n",
      "Train Epoch: 4 [8320/48000 (17%)]\tLoss: 0.052088\n",
      "Train Epoch: 4 [8960/48000 (19%)]\tLoss: 0.215628\n",
      "Train Epoch: 4 [9600/48000 (20%)]\tLoss: 0.084079\n",
      "Train Epoch: 4 [10240/48000 (21%)]\tLoss: 0.058552\n",
      "Train Epoch: 4 [10880/48000 (23%)]\tLoss: 0.127005\n",
      "Train Epoch: 4 [11520/48000 (24%)]\tLoss: 0.020441\n",
      "Train Epoch: 4 [12160/48000 (25%)]\tLoss: 0.042268\n",
      "Train Epoch: 4 [12800/48000 (27%)]\tLoss: 0.015392\n",
      "Train Epoch: 4 [13440/48000 (28%)]\tLoss: 0.054617\n",
      "Train Epoch: 4 [14080/48000 (29%)]\tLoss: 0.009022\n",
      "Train Epoch: 4 [14720/48000 (31%)]\tLoss: 0.063907\n",
      "Train Epoch: 4 [15360/48000 (32%)]\tLoss: 0.031025\n",
      "Train Epoch: 4 [16000/48000 (33%)]\tLoss: 0.160324\n",
      "Train Epoch: 4 [16640/48000 (35%)]\tLoss: 0.071284\n",
      "Train Epoch: 4 [17280/48000 (36%)]\tLoss: 0.041132\n",
      "Train Epoch: 4 [17920/48000 (37%)]\tLoss: 0.035559\n",
      "Train Epoch: 4 [18560/48000 (39%)]\tLoss: 0.034984\n",
      "Train Epoch: 4 [19200/48000 (40%)]\tLoss: 0.050654\n",
      "Train Epoch: 4 [19840/48000 (41%)]\tLoss: 0.018812\n",
      "Train Epoch: 4 [20480/48000 (43%)]\tLoss: 0.078921\n",
      "Train Epoch: 4 [21120/48000 (44%)]\tLoss: 0.091091\n",
      "Train Epoch: 4 [21760/48000 (45%)]\tLoss: 0.047788\n",
      "Train Epoch: 4 [22400/48000 (47%)]\tLoss: 0.112809\n",
      "Train Epoch: 4 [23040/48000 (48%)]\tLoss: 0.008348\n",
      "Train Epoch: 4 [23680/48000 (49%)]\tLoss: 0.023471\n",
      "Train Epoch: 4 [24320/48000 (51%)]\tLoss: 0.007911\n",
      "Train Epoch: 4 [24960/48000 (52%)]\tLoss: 0.005145\n",
      "Train Epoch: 4 [25600/48000 (53%)]\tLoss: 0.016291\n",
      "Train Epoch: 4 [26240/48000 (55%)]\tLoss: 0.014909\n",
      "Train Epoch: 4 [26880/48000 (56%)]\tLoss: 0.026443\n",
      "Train Epoch: 4 [27520/48000 (57%)]\tLoss: 0.079351\n",
      "Train Epoch: 4 [28160/48000 (59%)]\tLoss: 0.133110\n",
      "Train Epoch: 4 [28800/48000 (60%)]\tLoss: 0.045926\n",
      "Train Epoch: 4 [29440/48000 (61%)]\tLoss: 0.089264\n",
      "Train Epoch: 4 [30080/48000 (63%)]\tLoss: 0.033601\n",
      "Train Epoch: 4 [30720/48000 (64%)]\tLoss: 0.031701\n",
      "Train Epoch: 4 [31360/48000 (65%)]\tLoss: 0.060341\n",
      "Train Epoch: 4 [32000/48000 (67%)]\tLoss: 0.022312\n",
      "Train Epoch: 4 [32640/48000 (68%)]\tLoss: 0.017432\n",
      "Train Epoch: 4 [33280/48000 (69%)]\tLoss: 0.164732\n",
      "Train Epoch: 4 [33920/48000 (71%)]\tLoss: 0.038230\n",
      "Train Epoch: 4 [34560/48000 (72%)]\tLoss: 0.039977\n",
      "Train Epoch: 4 [35200/48000 (73%)]\tLoss: 0.019542\n",
      "Train Epoch: 4 [35840/48000 (75%)]\tLoss: 0.070481\n",
      "Train Epoch: 4 [36480/48000 (76%)]\tLoss: 0.039813\n",
      "Train Epoch: 4 [37120/48000 (77%)]\tLoss: 0.025000\n",
      "Train Epoch: 4 [37760/48000 (79%)]\tLoss: 0.159390\n",
      "Train Epoch: 4 [38400/48000 (80%)]\tLoss: 0.051544\n",
      "Train Epoch: 4 [39040/48000 (81%)]\tLoss: 0.004264\n",
      "Train Epoch: 4 [39680/48000 (83%)]\tLoss: 0.004744\n",
      "Train Epoch: 4 [40320/48000 (84%)]\tLoss: 0.004213\n",
      "Train Epoch: 4 [40960/48000 (85%)]\tLoss: 0.048703\n",
      "Train Epoch: 4 [41600/48000 (87%)]\tLoss: 0.090751\n",
      "Train Epoch: 4 [42240/48000 (88%)]\tLoss: 0.151686\n",
      "Train Epoch: 4 [42880/48000 (89%)]\tLoss: 0.128608\n",
      "Train Epoch: 4 [43520/48000 (91%)]\tLoss: 0.008784\n",
      "Train Epoch: 4 [44160/48000 (92%)]\tLoss: 0.037046\n",
      "Train Epoch: 4 [44800/48000 (93%)]\tLoss: 0.151649\n",
      "Train Epoch: 4 [45440/48000 (95%)]\tLoss: 0.038312\n",
      "Train Epoch: 4 [46080/48000 (96%)]\tLoss: 0.057210\n",
      "Train Epoch: 4 [46720/48000 (97%)]\tLoss: 0.103912\n",
      "Train Epoch: 4 [47360/48000 (99%)]\tLoss: 0.024566\n",
      "\n",
      "Test set: Average loss: 0.0552, Accuracy: 11798/12000 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/48000 (0%)]\tLoss: 0.064056\n",
      "Train Epoch: 5 [640/48000 (1%)]\tLoss: 0.026169\n",
      "Train Epoch: 5 [1280/48000 (3%)]\tLoss: 0.054003\n",
      "Train Epoch: 5 [1920/48000 (4%)]\tLoss: 0.048488\n",
      "Train Epoch: 5 [2560/48000 (5%)]\tLoss: 0.044390\n",
      "Train Epoch: 5 [3200/48000 (7%)]\tLoss: 0.009548\n",
      "Train Epoch: 5 [3840/48000 (8%)]\tLoss: 0.040733\n",
      "Train Epoch: 5 [4480/48000 (9%)]\tLoss: 0.085187\n",
      "Train Epoch: 5 [5120/48000 (11%)]\tLoss: 0.117628\n",
      "Train Epoch: 5 [5760/48000 (12%)]\tLoss: 0.016559\n",
      "Train Epoch: 5 [6400/48000 (13%)]\tLoss: 0.010048\n",
      "Train Epoch: 5 [7040/48000 (15%)]\tLoss: 0.040259\n",
      "Train Epoch: 5 [7680/48000 (16%)]\tLoss: 0.023129\n",
      "Train Epoch: 5 [8320/48000 (17%)]\tLoss: 0.017412\n",
      "Train Epoch: 5 [8960/48000 (19%)]\tLoss: 0.028782\n",
      "Train Epoch: 5 [9600/48000 (20%)]\tLoss: 0.063403\n",
      "Train Epoch: 5 [10240/48000 (21%)]\tLoss: 0.043417\n",
      "Train Epoch: 5 [10880/48000 (23%)]\tLoss: 0.108010\n",
      "Train Epoch: 5 [11520/48000 (24%)]\tLoss: 0.088090\n",
      "Train Epoch: 5 [12160/48000 (25%)]\tLoss: 0.053590\n",
      "Train Epoch: 5 [12800/48000 (27%)]\tLoss: 0.084858\n",
      "Train Epoch: 5 [13440/48000 (28%)]\tLoss: 0.067416\n",
      "Train Epoch: 5 [14080/48000 (29%)]\tLoss: 0.007634\n",
      "Train Epoch: 5 [14720/48000 (31%)]\tLoss: 0.134835\n",
      "Train Epoch: 5 [15360/48000 (32%)]\tLoss: 0.023618\n",
      "Train Epoch: 5 [16000/48000 (33%)]\tLoss: 0.105905\n",
      "Train Epoch: 5 [16640/48000 (35%)]\tLoss: 0.124099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [17280/48000 (36%)]\tLoss: 0.141348\n",
      "Train Epoch: 5 [17920/48000 (37%)]\tLoss: 0.010323\n",
      "Train Epoch: 5 [18560/48000 (39%)]\tLoss: 0.009589\n",
      "Train Epoch: 5 [19200/48000 (40%)]\tLoss: 0.130690\n",
      "Train Epoch: 5 [19840/48000 (41%)]\tLoss: 0.028742\n",
      "Train Epoch: 5 [20480/48000 (43%)]\tLoss: 0.040320\n",
      "Train Epoch: 5 [21120/48000 (44%)]\tLoss: 0.064771\n",
      "Train Epoch: 5 [21760/48000 (45%)]\tLoss: 0.029939\n",
      "Train Epoch: 5 [22400/48000 (47%)]\tLoss: 0.048700\n",
      "Train Epoch: 5 [23040/48000 (48%)]\tLoss: 0.065514\n",
      "Train Epoch: 5 [23680/48000 (49%)]\tLoss: 0.189596\n",
      "Train Epoch: 5 [24320/48000 (51%)]\tLoss: 0.112338\n",
      "Train Epoch: 5 [24960/48000 (52%)]\tLoss: 0.033283\n",
      "Train Epoch: 5 [25600/48000 (53%)]\tLoss: 0.011056\n",
      "Train Epoch: 5 [26240/48000 (55%)]\tLoss: 0.029101\n",
      "Train Epoch: 5 [26880/48000 (56%)]\tLoss: 0.010149\n",
      "Train Epoch: 5 [27520/48000 (57%)]\tLoss: 0.012708\n",
      "Train Epoch: 5 [28160/48000 (59%)]\tLoss: 0.162822\n",
      "Train Epoch: 5 [28800/48000 (60%)]\tLoss: 0.003014\n",
      "Train Epoch: 5 [29440/48000 (61%)]\tLoss: 0.030579\n",
      "Train Epoch: 5 [30080/48000 (63%)]\tLoss: 0.011054\n",
      "Train Epoch: 5 [30720/48000 (64%)]\tLoss: 0.055462\n",
      "Train Epoch: 5 [31360/48000 (65%)]\tLoss: 0.013031\n",
      "Train Epoch: 5 [32000/48000 (67%)]\tLoss: 0.033084\n",
      "Train Epoch: 5 [32640/48000 (68%)]\tLoss: 0.034490\n",
      "Train Epoch: 5 [33280/48000 (69%)]\tLoss: 0.012316\n",
      "Train Epoch: 5 [33920/48000 (71%)]\tLoss: 0.078153\n",
      "Train Epoch: 5 [34560/48000 (72%)]\tLoss: 0.013670\n",
      "Train Epoch: 5 [35200/48000 (73%)]\tLoss: 0.007485\n",
      "Train Epoch: 5 [35840/48000 (75%)]\tLoss: 0.045588\n",
      "Train Epoch: 5 [36480/48000 (76%)]\tLoss: 0.113061\n",
      "Train Epoch: 5 [37120/48000 (77%)]\tLoss: 0.015461\n",
      "Train Epoch: 5 [37760/48000 (79%)]\tLoss: 0.054805\n",
      "Train Epoch: 5 [38400/48000 (80%)]\tLoss: 0.036751\n",
      "Train Epoch: 5 [39040/48000 (81%)]\tLoss: 0.014407\n",
      "Train Epoch: 5 [39680/48000 (83%)]\tLoss: 0.003263\n",
      "Train Epoch: 5 [40320/48000 (84%)]\tLoss: 0.048358\n",
      "Train Epoch: 5 [40960/48000 (85%)]\tLoss: 0.008204\n",
      "Train Epoch: 5 [41600/48000 (87%)]\tLoss: 0.050317\n",
      "Train Epoch: 5 [42240/48000 (88%)]\tLoss: 0.086257\n",
      "Train Epoch: 5 [42880/48000 (89%)]\tLoss: 0.043058\n",
      "Train Epoch: 5 [43520/48000 (91%)]\tLoss: 0.029270\n",
      "Train Epoch: 5 [44160/48000 (92%)]\tLoss: 0.042478\n",
      "Train Epoch: 5 [44800/48000 (93%)]\tLoss: 0.017282\n",
      "Train Epoch: 5 [45440/48000 (95%)]\tLoss: 0.009682\n",
      "Train Epoch: 5 [46080/48000 (96%)]\tLoss: 0.008992\n",
      "Train Epoch: 5 [46720/48000 (97%)]\tLoss: 0.068846\n",
      "Train Epoch: 5 [47360/48000 (99%)]\tLoss: 0.275056\n",
      "\n",
      "Test set: Average loss: 0.0480, Accuracy: 11814/12000 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/48000 (0%)]\tLoss: 0.028500\n",
      "Train Epoch: 6 [640/48000 (1%)]\tLoss: 0.073059\n",
      "Train Epoch: 6 [1280/48000 (3%)]\tLoss: 0.024214\n",
      "Train Epoch: 6 [1920/48000 (4%)]\tLoss: 0.048324\n",
      "Train Epoch: 6 [2560/48000 (5%)]\tLoss: 0.010049\n",
      "Train Epoch: 6 [3200/48000 (7%)]\tLoss: 0.007323\n",
      "Train Epoch: 6 [3840/48000 (8%)]\tLoss: 0.028450\n",
      "Train Epoch: 6 [4480/48000 (9%)]\tLoss: 0.027841\n",
      "Train Epoch: 6 [5120/48000 (11%)]\tLoss: 0.004637\n",
      "Train Epoch: 6 [5760/48000 (12%)]\tLoss: 0.003394\n",
      "Train Epoch: 6 [6400/48000 (13%)]\tLoss: 0.042207\n",
      "Train Epoch: 6 [7040/48000 (15%)]\tLoss: 0.004413\n",
      "Train Epoch: 6 [7680/48000 (16%)]\tLoss: 0.026711\n",
      "Train Epoch: 6 [8320/48000 (17%)]\tLoss: 0.022544\n",
      "Train Epoch: 6 [8960/48000 (19%)]\tLoss: 0.034979\n",
      "Train Epoch: 6 [9600/48000 (20%)]\tLoss: 0.002750\n",
      "Train Epoch: 6 [10240/48000 (21%)]\tLoss: 0.038000\n",
      "Train Epoch: 6 [10880/48000 (23%)]\tLoss: 0.011581\n",
      "Train Epoch: 6 [11520/48000 (24%)]\tLoss: 0.030162\n",
      "Train Epoch: 6 [12160/48000 (25%)]\tLoss: 0.054587\n",
      "Train Epoch: 6 [12800/48000 (27%)]\tLoss: 0.011713\n",
      "Train Epoch: 6 [13440/48000 (28%)]\tLoss: 0.065886\n",
      "Train Epoch: 6 [14080/48000 (29%)]\tLoss: 0.035620\n",
      "Train Epoch: 6 [14720/48000 (31%)]\tLoss: 0.037847\n",
      "Train Epoch: 6 [15360/48000 (32%)]\tLoss: 0.022591\n",
      "Train Epoch: 6 [16000/48000 (33%)]\tLoss: 0.005751\n",
      "Train Epoch: 6 [16640/48000 (35%)]\tLoss: 0.007008\n",
      "Train Epoch: 6 [17280/48000 (36%)]\tLoss: 0.032430\n",
      "Train Epoch: 6 [17920/48000 (37%)]\tLoss: 0.290307\n",
      "Train Epoch: 6 [18560/48000 (39%)]\tLoss: 0.068638\n",
      "Train Epoch: 6 [19200/48000 (40%)]\tLoss: 0.015017\n",
      "Train Epoch: 6 [19840/48000 (41%)]\tLoss: 0.042274\n",
      "Train Epoch: 6 [20480/48000 (43%)]\tLoss: 0.008240\n",
      "Train Epoch: 6 [21120/48000 (44%)]\tLoss: 0.064886\n",
      "Train Epoch: 6 [21760/48000 (45%)]\tLoss: 0.008293\n",
      "Train Epoch: 6 [22400/48000 (47%)]\tLoss: 0.065922\n",
      "Train Epoch: 6 [23040/48000 (48%)]\tLoss: 0.014635\n",
      "Train Epoch: 6 [23680/48000 (49%)]\tLoss: 0.029196\n",
      "Train Epoch: 6 [24320/48000 (51%)]\tLoss: 0.072243\n",
      "Train Epoch: 6 [24960/48000 (52%)]\tLoss: 0.026193\n",
      "Train Epoch: 6 [25600/48000 (53%)]\tLoss: 0.025114\n",
      "Train Epoch: 6 [26240/48000 (55%)]\tLoss: 0.005026\n",
      "Train Epoch: 6 [26880/48000 (56%)]\tLoss: 0.013082\n",
      "Train Epoch: 6 [27520/48000 (57%)]\tLoss: 0.208065\n",
      "Train Epoch: 6 [28160/48000 (59%)]\tLoss: 0.024986\n",
      "Train Epoch: 6 [28800/48000 (60%)]\tLoss: 0.014103\n",
      "Train Epoch: 6 [29440/48000 (61%)]\tLoss: 0.102178\n",
      "Train Epoch: 6 [30080/48000 (63%)]\tLoss: 0.027820\n",
      "Train Epoch: 6 [30720/48000 (64%)]\tLoss: 0.104529\n",
      "Train Epoch: 6 [31360/48000 (65%)]\tLoss: 0.015522\n",
      "Train Epoch: 6 [32000/48000 (67%)]\tLoss: 0.028924\n",
      "Train Epoch: 6 [32640/48000 (68%)]\tLoss: 0.061583\n",
      "Train Epoch: 6 [33280/48000 (69%)]\tLoss: 0.031278\n",
      "Train Epoch: 6 [33920/48000 (71%)]\tLoss: 0.021609\n",
      "Train Epoch: 6 [34560/48000 (72%)]\tLoss: 0.029198\n",
      "Train Epoch: 6 [35200/48000 (73%)]\tLoss: 0.038882\n",
      "Train Epoch: 6 [35840/48000 (75%)]\tLoss: 0.059702\n",
      "Train Epoch: 6 [36480/48000 (76%)]\tLoss: 0.006809\n",
      "Train Epoch: 6 [37120/48000 (77%)]\tLoss: 0.057280\n",
      "Train Epoch: 6 [37760/48000 (79%)]\tLoss: 0.011386\n",
      "Train Epoch: 6 [38400/48000 (80%)]\tLoss: 0.041498\n",
      "Train Epoch: 6 [39040/48000 (81%)]\tLoss: 0.060147\n",
      "Train Epoch: 6 [39680/48000 (83%)]\tLoss: 0.048079\n",
      "Train Epoch: 6 [40320/48000 (84%)]\tLoss: 0.058562\n",
      "Train Epoch: 6 [40960/48000 (85%)]\tLoss: 0.013370\n",
      "Train Epoch: 6 [41600/48000 (87%)]\tLoss: 0.020587\n",
      "Train Epoch: 6 [42240/48000 (88%)]\tLoss: 0.113972\n",
      "Train Epoch: 6 [42880/48000 (89%)]\tLoss: 0.077764\n",
      "Train Epoch: 6 [43520/48000 (91%)]\tLoss: 0.029930\n",
      "Train Epoch: 6 [44160/48000 (92%)]\tLoss: 0.091694\n",
      "Train Epoch: 6 [44800/48000 (93%)]\tLoss: 0.032771\n",
      "Train Epoch: 6 [45440/48000 (95%)]\tLoss: 0.009691\n",
      "Train Epoch: 6 [46080/48000 (96%)]\tLoss: 0.064965\n",
      "Train Epoch: 6 [46720/48000 (97%)]\tLoss: 0.066351\n",
      "Train Epoch: 6 [47360/48000 (99%)]\tLoss: 0.010065\n",
      "\n",
      "Test set: Average loss: 0.0465, Accuracy: 11821/12000 (99%)\n",
      "\n",
      "Train Epoch: 7 [0/48000 (0%)]\tLoss: 0.029355\n",
      "Train Epoch: 7 [640/48000 (1%)]\tLoss: 0.013590\n",
      "Train Epoch: 7 [1280/48000 (3%)]\tLoss: 0.020828\n",
      "Train Epoch: 7 [1920/48000 (4%)]\tLoss: 0.008039\n",
      "Train Epoch: 7 [2560/48000 (5%)]\tLoss: 0.046328\n",
      "Train Epoch: 7 [3200/48000 (7%)]\tLoss: 0.062696\n",
      "Train Epoch: 7 [3840/48000 (8%)]\tLoss: 0.043992\n",
      "Train Epoch: 7 [4480/48000 (9%)]\tLoss: 0.025030\n",
      "Train Epoch: 7 [5120/48000 (11%)]\tLoss: 0.008040\n",
      "Train Epoch: 7 [5760/48000 (12%)]\tLoss: 0.023435\n",
      "Train Epoch: 7 [6400/48000 (13%)]\tLoss: 0.072108\n",
      "Train Epoch: 7 [7040/48000 (15%)]\tLoss: 0.173104\n",
      "Train Epoch: 7 [7680/48000 (16%)]\tLoss: 0.024735\n",
      "Train Epoch: 7 [8320/48000 (17%)]\tLoss: 0.025171\n",
      "Train Epoch: 7 [8960/48000 (19%)]\tLoss: 0.008937\n",
      "Train Epoch: 7 [9600/48000 (20%)]\tLoss: 0.135310\n",
      "Train Epoch: 7 [10240/48000 (21%)]\tLoss: 0.062501\n",
      "Train Epoch: 7 [10880/48000 (23%)]\tLoss: 0.033719\n",
      "Train Epoch: 7 [11520/48000 (24%)]\tLoss: 0.043203\n",
      "Train Epoch: 7 [12160/48000 (25%)]\tLoss: 0.069679\n",
      "Train Epoch: 7 [12800/48000 (27%)]\tLoss: 0.092798\n",
      "Train Epoch: 7 [13440/48000 (28%)]\tLoss: 0.011596\n",
      "Train Epoch: 7 [14080/48000 (29%)]\tLoss: 0.120566\n",
      "Train Epoch: 7 [14720/48000 (31%)]\tLoss: 0.021567\n",
      "Train Epoch: 7 [15360/48000 (32%)]\tLoss: 0.020037\n",
      "Train Epoch: 7 [16000/48000 (33%)]\tLoss: 0.024076\n",
      "Train Epoch: 7 [16640/48000 (35%)]\tLoss: 0.011619\n",
      "Train Epoch: 7 [17280/48000 (36%)]\tLoss: 0.005049\n",
      "Train Epoch: 7 [17920/48000 (37%)]\tLoss: 0.004188\n",
      "Train Epoch: 7 [18560/48000 (39%)]\tLoss: 0.032238\n",
      "Train Epoch: 7 [19200/48000 (40%)]\tLoss: 0.032892\n",
      "Train Epoch: 7 [19840/48000 (41%)]\tLoss: 0.039644\n",
      "Train Epoch: 7 [20480/48000 (43%)]\tLoss: 0.056671\n",
      "Train Epoch: 7 [21120/48000 (44%)]\tLoss: 0.010539\n",
      "Train Epoch: 7 [21760/48000 (45%)]\tLoss: 0.023223\n",
      "Train Epoch: 7 [22400/48000 (47%)]\tLoss: 0.014971\n",
      "Train Epoch: 7 [23040/48000 (48%)]\tLoss: 0.011883\n",
      "Train Epoch: 7 [23680/48000 (49%)]\tLoss: 0.006963\n",
      "Train Epoch: 7 [24320/48000 (51%)]\tLoss: 0.011936\n",
      "Train Epoch: 7 [24960/48000 (52%)]\tLoss: 0.053558\n",
      "Train Epoch: 7 [25600/48000 (53%)]\tLoss: 0.056974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [26240/48000 (55%)]\tLoss: 0.006463\n",
      "Train Epoch: 7 [26880/48000 (56%)]\tLoss: 0.017177\n",
      "Train Epoch: 7 [27520/48000 (57%)]\tLoss: 0.032740\n",
      "Train Epoch: 7 [28160/48000 (59%)]\tLoss: 0.087122\n",
      "Train Epoch: 7 [28800/48000 (60%)]\tLoss: 0.014871\n",
      "Train Epoch: 7 [29440/48000 (61%)]\tLoss: 0.048038\n",
      "Train Epoch: 7 [30080/48000 (63%)]\tLoss: 0.068651\n",
      "Train Epoch: 7 [30720/48000 (64%)]\tLoss: 0.248489\n",
      "Train Epoch: 7 [31360/48000 (65%)]\tLoss: 0.013784\n",
      "Train Epoch: 7 [32000/48000 (67%)]\tLoss: 0.070649\n",
      "Train Epoch: 7 [32640/48000 (68%)]\tLoss: 0.011419\n",
      "Train Epoch: 7 [33280/48000 (69%)]\tLoss: 0.035500\n",
      "Train Epoch: 7 [33920/48000 (71%)]\tLoss: 0.004098\n",
      "Train Epoch: 7 [34560/48000 (72%)]\tLoss: 0.051297\n",
      "Train Epoch: 7 [35200/48000 (73%)]\tLoss: 0.010613\n",
      "Train Epoch: 7 [35840/48000 (75%)]\tLoss: 0.006698\n",
      "Train Epoch: 7 [36480/48000 (76%)]\tLoss: 0.011104\n",
      "Train Epoch: 7 [37120/48000 (77%)]\tLoss: 0.033234\n",
      "Train Epoch: 7 [37760/48000 (79%)]\tLoss: 0.041097\n",
      "Train Epoch: 7 [38400/48000 (80%)]\tLoss: 0.027114\n",
      "Train Epoch: 7 [39040/48000 (81%)]\tLoss: 0.030663\n",
      "Train Epoch: 7 [39680/48000 (83%)]\tLoss: 0.128138\n",
      "Train Epoch: 7 [40320/48000 (84%)]\tLoss: 0.110702\n",
      "Train Epoch: 7 [40960/48000 (85%)]\tLoss: 0.089075\n",
      "Train Epoch: 7 [41600/48000 (87%)]\tLoss: 0.014569\n",
      "Train Epoch: 7 [42240/48000 (88%)]\tLoss: 0.002241\n",
      "Train Epoch: 7 [42880/48000 (89%)]\tLoss: 0.010814\n",
      "Train Epoch: 7 [43520/48000 (91%)]\tLoss: 0.084175\n",
      "Train Epoch: 7 [44160/48000 (92%)]\tLoss: 0.035773\n",
      "Train Epoch: 7 [44800/48000 (93%)]\tLoss: 0.042126\n",
      "Train Epoch: 7 [45440/48000 (95%)]\tLoss: 0.026592\n",
      "Train Epoch: 7 [46080/48000 (96%)]\tLoss: 0.177377\n",
      "Train Epoch: 7 [46720/48000 (97%)]\tLoss: 0.003294\n",
      "Train Epoch: 7 [47360/48000 (99%)]\tLoss: 0.006369\n",
      "\n",
      "Test set: Average loss: 0.0423, Accuracy: 11845/12000 (99%)\n",
      "\n",
      "Train Epoch: 8 [0/48000 (0%)]\tLoss: 0.003755\n",
      "Train Epoch: 8 [640/48000 (1%)]\tLoss: 0.002434\n",
      "Train Epoch: 8 [1280/48000 (3%)]\tLoss: 0.071248\n",
      "Train Epoch: 8 [1920/48000 (4%)]\tLoss: 0.030850\n",
      "Train Epoch: 8 [2560/48000 (5%)]\tLoss: 0.018911\n",
      "Train Epoch: 8 [3200/48000 (7%)]\tLoss: 0.065480\n",
      "Train Epoch: 8 [3840/48000 (8%)]\tLoss: 0.044378\n",
      "Train Epoch: 8 [4480/48000 (9%)]\tLoss: 0.003214\n",
      "Train Epoch: 8 [5120/48000 (11%)]\tLoss: 0.006919\n",
      "Train Epoch: 8 [5760/48000 (12%)]\tLoss: 0.093391\n",
      "Train Epoch: 8 [6400/48000 (13%)]\tLoss: 0.015718\n",
      "Train Epoch: 8 [7040/48000 (15%)]\tLoss: 0.010507\n",
      "Train Epoch: 8 [7680/48000 (16%)]\tLoss: 0.010119\n",
      "Train Epoch: 8 [8320/48000 (17%)]\tLoss: 0.020348\n",
      "Train Epoch: 8 [8960/48000 (19%)]\tLoss: 0.012883\n",
      "Train Epoch: 8 [9600/48000 (20%)]\tLoss: 0.019031\n",
      "Train Epoch: 8 [10240/48000 (21%)]\tLoss: 0.047200\n",
      "Train Epoch: 8 [10880/48000 (23%)]\tLoss: 0.056697\n",
      "Train Epoch: 8 [11520/48000 (24%)]\tLoss: 0.026853\n",
      "Train Epoch: 8 [12160/48000 (25%)]\tLoss: 0.026845\n",
      "Train Epoch: 8 [12800/48000 (27%)]\tLoss: 0.013463\n",
      "Train Epoch: 8 [13440/48000 (28%)]\tLoss: 0.085946\n",
      "Train Epoch: 8 [14080/48000 (29%)]\tLoss: 0.012411\n",
      "Train Epoch: 8 [14720/48000 (31%)]\tLoss: 0.048172\n",
      "Train Epoch: 8 [15360/48000 (32%)]\tLoss: 0.007432\n",
      "Train Epoch: 8 [16000/48000 (33%)]\tLoss: 0.017166\n",
      "Train Epoch: 8 [16640/48000 (35%)]\tLoss: 0.023652\n",
      "Train Epoch: 8 [17280/48000 (36%)]\tLoss: 0.013091\n",
      "Train Epoch: 8 [17920/48000 (37%)]\tLoss: 0.009196\n",
      "Train Epoch: 8 [18560/48000 (39%)]\tLoss: 0.007644\n",
      "Train Epoch: 8 [19200/48000 (40%)]\tLoss: 0.026688\n",
      "Train Epoch: 8 [19840/48000 (41%)]\tLoss: 0.006719\n",
      "Train Epoch: 8 [20480/48000 (43%)]\tLoss: 0.066280\n",
      "Train Epoch: 8 [21120/48000 (44%)]\tLoss: 0.039287\n",
      "Train Epoch: 8 [21760/48000 (45%)]\tLoss: 0.023094\n",
      "Train Epoch: 8 [22400/48000 (47%)]\tLoss: 0.005251\n",
      "Train Epoch: 8 [23040/48000 (48%)]\tLoss: 0.152099\n",
      "Train Epoch: 8 [23680/48000 (49%)]\tLoss: 0.119298\n",
      "Train Epoch: 8 [24320/48000 (51%)]\tLoss: 0.037473\n",
      "Train Epoch: 8 [24960/48000 (52%)]\tLoss: 0.045019\n",
      "Train Epoch: 8 [25600/48000 (53%)]\tLoss: 0.007912\n",
      "Train Epoch: 8 [26240/48000 (55%)]\tLoss: 0.008450\n",
      "Train Epoch: 8 [26880/48000 (56%)]\tLoss: 0.011987\n",
      "Train Epoch: 8 [27520/48000 (57%)]\tLoss: 0.092269\n",
      "Train Epoch: 8 [28160/48000 (59%)]\tLoss: 0.019169\n",
      "Train Epoch: 8 [28800/48000 (60%)]\tLoss: 0.045996\n",
      "Train Epoch: 8 [29440/48000 (61%)]\tLoss: 0.014115\n",
      "Train Epoch: 8 [30080/48000 (63%)]\tLoss: 0.013351\n",
      "Train Epoch: 8 [30720/48000 (64%)]\tLoss: 0.002623\n",
      "Train Epoch: 8 [31360/48000 (65%)]\tLoss: 0.101868\n",
      "Train Epoch: 8 [32000/48000 (67%)]\tLoss: 0.025905\n",
      "Train Epoch: 8 [32640/48000 (68%)]\tLoss: 0.007116\n",
      "Train Epoch: 8 [33280/48000 (69%)]\tLoss: 0.010978\n",
      "Train Epoch: 8 [33920/48000 (71%)]\tLoss: 0.016323\n",
      "Train Epoch: 8 [34560/48000 (72%)]\tLoss: 0.007066\n",
      "Train Epoch: 8 [35200/48000 (73%)]\tLoss: 0.092235\n",
      "Train Epoch: 8 [35840/48000 (75%)]\tLoss: 0.003577\n",
      "Train Epoch: 8 [36480/48000 (76%)]\tLoss: 0.019298\n",
      "Train Epoch: 8 [37120/48000 (77%)]\tLoss: 0.019973\n",
      "Train Epoch: 8 [37760/48000 (79%)]\tLoss: 0.004514\n",
      "Train Epoch: 8 [38400/48000 (80%)]\tLoss: 0.039044\n",
      "Train Epoch: 8 [39040/48000 (81%)]\tLoss: 0.008595\n",
      "Train Epoch: 8 [39680/48000 (83%)]\tLoss: 0.005969\n",
      "Train Epoch: 8 [40320/48000 (84%)]\tLoss: 0.015394\n",
      "Train Epoch: 8 [40960/48000 (85%)]\tLoss: 0.035604\n",
      "Train Epoch: 8 [41600/48000 (87%)]\tLoss: 0.002077\n",
      "Train Epoch: 8 [42240/48000 (88%)]\tLoss: 0.130767\n",
      "Train Epoch: 8 [42880/48000 (89%)]\tLoss: 0.003564\n",
      "Train Epoch: 8 [43520/48000 (91%)]\tLoss: 0.021697\n",
      "Train Epoch: 8 [44160/48000 (92%)]\tLoss: 0.043123\n",
      "Train Epoch: 8 [44800/48000 (93%)]\tLoss: 0.003762\n",
      "Train Epoch: 8 [45440/48000 (95%)]\tLoss: 0.014425\n",
      "Train Epoch: 8 [46080/48000 (96%)]\tLoss: 0.046856\n",
      "Train Epoch: 8 [46720/48000 (97%)]\tLoss: 0.063297\n",
      "Train Epoch: 8 [47360/48000 (99%)]\tLoss: 0.002694\n",
      "\n",
      "Test set: Average loss: 0.0410, Accuracy: 11851/12000 (99%)\n",
      "\n",
      "Train Epoch: 9 [0/48000 (0%)]\tLoss: 0.004454\n",
      "Train Epoch: 9 [640/48000 (1%)]\tLoss: 0.015673\n",
      "Train Epoch: 9 [1280/48000 (3%)]\tLoss: 0.001026\n",
      "Train Epoch: 9 [1920/48000 (4%)]\tLoss: 0.004606\n",
      "Train Epoch: 9 [2560/48000 (5%)]\tLoss: 0.017802\n",
      "Train Epoch: 9 [3200/48000 (7%)]\tLoss: 0.012705\n",
      "Train Epoch: 9 [3840/48000 (8%)]\tLoss: 0.048849\n",
      "Train Epoch: 9 [4480/48000 (9%)]\tLoss: 0.002869\n",
      "Train Epoch: 9 [5120/48000 (11%)]\tLoss: 0.022278\n",
      "Train Epoch: 9 [5760/48000 (12%)]\tLoss: 0.025825\n",
      "Train Epoch: 9 [6400/48000 (13%)]\tLoss: 0.003985\n",
      "Train Epoch: 9 [7040/48000 (15%)]\tLoss: 0.005577\n",
      "Train Epoch: 9 [7680/48000 (16%)]\tLoss: 0.000644\n",
      "Train Epoch: 9 [8320/48000 (17%)]\tLoss: 0.053813\n",
      "Train Epoch: 9 [8960/48000 (19%)]\tLoss: 0.007217\n",
      "Train Epoch: 9 [9600/48000 (20%)]\tLoss: 0.011177\n",
      "Train Epoch: 9 [10240/48000 (21%)]\tLoss: 0.011171\n",
      "Train Epoch: 9 [10880/48000 (23%)]\tLoss: 0.006560\n",
      "Train Epoch: 9 [11520/48000 (24%)]\tLoss: 0.011473\n",
      "Train Epoch: 9 [12160/48000 (25%)]\tLoss: 0.079319\n",
      "Train Epoch: 9 [12800/48000 (27%)]\tLoss: 0.015669\n",
      "Train Epoch: 9 [13440/48000 (28%)]\tLoss: 0.019203\n",
      "Train Epoch: 9 [14080/48000 (29%)]\tLoss: 0.016182\n",
      "Train Epoch: 9 [14720/48000 (31%)]\tLoss: 0.039226\n",
      "Train Epoch: 9 [15360/48000 (32%)]\tLoss: 0.002407\n",
      "Train Epoch: 9 [16000/48000 (33%)]\tLoss: 0.110791\n",
      "Train Epoch: 9 [16640/48000 (35%)]\tLoss: 0.016019\n",
      "Train Epoch: 9 [17280/48000 (36%)]\tLoss: 0.011909\n",
      "Train Epoch: 9 [17920/48000 (37%)]\tLoss: 0.055907\n",
      "Train Epoch: 9 [18560/48000 (39%)]\tLoss: 0.026997\n",
      "Train Epoch: 9 [19200/48000 (40%)]\tLoss: 0.088953\n",
      "Train Epoch: 9 [19840/48000 (41%)]\tLoss: 0.058193\n",
      "Train Epoch: 9 [20480/48000 (43%)]\tLoss: 0.030240\n",
      "Train Epoch: 9 [21120/48000 (44%)]\tLoss: 0.019334\n",
      "Train Epoch: 9 [21760/48000 (45%)]\tLoss: 0.027066\n",
      "Train Epoch: 9 [22400/48000 (47%)]\tLoss: 0.020891\n",
      "Train Epoch: 9 [23040/48000 (48%)]\tLoss: 0.007352\n",
      "Train Epoch: 9 [23680/48000 (49%)]\tLoss: 0.005178\n",
      "Train Epoch: 9 [24320/48000 (51%)]\tLoss: 0.029479\n",
      "Train Epoch: 9 [24960/48000 (52%)]\tLoss: 0.012125\n",
      "Train Epoch: 9 [25600/48000 (53%)]\tLoss: 0.045721\n",
      "Train Epoch: 9 [26240/48000 (55%)]\tLoss: 0.011233\n",
      "Train Epoch: 9 [26880/48000 (56%)]\tLoss: 0.038069\n",
      "Train Epoch: 9 [27520/48000 (57%)]\tLoss: 0.000920\n",
      "Train Epoch: 9 [28160/48000 (59%)]\tLoss: 0.072955\n",
      "Train Epoch: 9 [28800/48000 (60%)]\tLoss: 0.027170\n",
      "Train Epoch: 9 [29440/48000 (61%)]\tLoss: 0.004602\n",
      "Train Epoch: 9 [30080/48000 (63%)]\tLoss: 0.003771\n",
      "Train Epoch: 9 [30720/48000 (64%)]\tLoss: 0.032684\n",
      "Train Epoch: 9 [31360/48000 (65%)]\tLoss: 0.009170\n",
      "Train Epoch: 9 [32000/48000 (67%)]\tLoss: 0.031847\n",
      "Train Epoch: 9 [32640/48000 (68%)]\tLoss: 0.004753\n",
      "Train Epoch: 9 [33280/48000 (69%)]\tLoss: 0.004967\n",
      "Train Epoch: 9 [33920/48000 (71%)]\tLoss: 0.017831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [34560/48000 (72%)]\tLoss: 0.004998\n",
      "Train Epoch: 9 [35200/48000 (73%)]\tLoss: 0.049873\n",
      "Train Epoch: 9 [35840/48000 (75%)]\tLoss: 0.011961\n",
      "Train Epoch: 9 [36480/48000 (76%)]\tLoss: 0.045829\n",
      "Train Epoch: 9 [37120/48000 (77%)]\tLoss: 0.189292\n",
      "Train Epoch: 9 [37760/48000 (79%)]\tLoss: 0.031288\n",
      "Train Epoch: 9 [38400/48000 (80%)]\tLoss: 0.014342\n",
      "Train Epoch: 9 [39040/48000 (81%)]\tLoss: 0.026238\n",
      "Train Epoch: 9 [39680/48000 (83%)]\tLoss: 0.120366\n",
      "Train Epoch: 9 [40320/48000 (84%)]\tLoss: 0.004979\n",
      "Train Epoch: 9 [40960/48000 (85%)]\tLoss: 0.010237\n",
      "Train Epoch: 9 [41600/48000 (87%)]\tLoss: 0.004310\n",
      "Train Epoch: 9 [42240/48000 (88%)]\tLoss: 0.011872\n",
      "Train Epoch: 9 [42880/48000 (89%)]\tLoss: 0.010639\n",
      "Train Epoch: 9 [43520/48000 (91%)]\tLoss: 0.001802\n",
      "Train Epoch: 9 [44160/48000 (92%)]\tLoss: 0.010125\n",
      "Train Epoch: 9 [44800/48000 (93%)]\tLoss: 0.030385\n",
      "Train Epoch: 9 [45440/48000 (95%)]\tLoss: 0.002050\n",
      "Train Epoch: 9 [46080/48000 (96%)]\tLoss: 0.025423\n",
      "Train Epoch: 9 [46720/48000 (97%)]\tLoss: 0.009868\n",
      "Train Epoch: 9 [47360/48000 (99%)]\tLoss: 0.081601\n",
      "\n",
      "Test set: Average loss: 0.0379, Accuracy: 11858/12000 (99%)\n",
      "\n",
      "Train Epoch: 10 [0/48000 (0%)]\tLoss: 0.003564\n",
      "Train Epoch: 10 [640/48000 (1%)]\tLoss: 0.076173\n",
      "Train Epoch: 10 [1280/48000 (3%)]\tLoss: 0.100104\n",
      "Train Epoch: 10 [1920/48000 (4%)]\tLoss: 0.001050\n",
      "Train Epoch: 10 [2560/48000 (5%)]\tLoss: 0.104016\n",
      "Train Epoch: 10 [3200/48000 (7%)]\tLoss: 0.016546\n",
      "Train Epoch: 10 [3840/48000 (8%)]\tLoss: 0.008615\n",
      "Train Epoch: 10 [4480/48000 (9%)]\tLoss: 0.011051\n",
      "Train Epoch: 10 [5120/48000 (11%)]\tLoss: 0.017353\n",
      "Train Epoch: 10 [5760/48000 (12%)]\tLoss: 0.009927\n",
      "Train Epoch: 10 [6400/48000 (13%)]\tLoss: 0.016775\n",
      "Train Epoch: 10 [7040/48000 (15%)]\tLoss: 0.011344\n",
      "Train Epoch: 10 [7680/48000 (16%)]\tLoss: 0.032672\n",
      "Train Epoch: 10 [8320/48000 (17%)]\tLoss: 0.010945\n",
      "Train Epoch: 10 [8960/48000 (19%)]\tLoss: 0.034227\n",
      "Train Epoch: 10 [9600/48000 (20%)]\tLoss: 0.017937\n",
      "Train Epoch: 10 [10240/48000 (21%)]\tLoss: 0.099677\n",
      "Train Epoch: 10 [10880/48000 (23%)]\tLoss: 0.003758\n",
      "Train Epoch: 10 [11520/48000 (24%)]\tLoss: 0.033443\n",
      "Train Epoch: 10 [12160/48000 (25%)]\tLoss: 0.058590\n",
      "Train Epoch: 10 [12800/48000 (27%)]\tLoss: 0.011571\n",
      "Train Epoch: 10 [13440/48000 (28%)]\tLoss: 0.006381\n",
      "Train Epoch: 10 [14080/48000 (29%)]\tLoss: 0.015162\n",
      "Train Epoch: 10 [14720/48000 (31%)]\tLoss: 0.045543\n",
      "Train Epoch: 10 [15360/48000 (32%)]\tLoss: 0.042640\n",
      "Train Epoch: 10 [16000/48000 (33%)]\tLoss: 0.028225\n",
      "Train Epoch: 10 [16640/48000 (35%)]\tLoss: 0.004439\n",
      "Train Epoch: 10 [17280/48000 (36%)]\tLoss: 0.003739\n",
      "Train Epoch: 10 [17920/48000 (37%)]\tLoss: 0.002440\n",
      "Train Epoch: 10 [18560/48000 (39%)]\tLoss: 0.016280\n",
      "Train Epoch: 10 [19200/48000 (40%)]\tLoss: 0.006160\n",
      "Train Epoch: 10 [19840/48000 (41%)]\tLoss: 0.010619\n",
      "Train Epoch: 10 [20480/48000 (43%)]\tLoss: 0.044720\n",
      "Train Epoch: 10 [21120/48000 (44%)]\tLoss: 0.010312\n",
      "Train Epoch: 10 [21760/48000 (45%)]\tLoss: 0.007908\n",
      "Train Epoch: 10 [22400/48000 (47%)]\tLoss: 0.013779\n",
      "Train Epoch: 10 [23040/48000 (48%)]\tLoss: 0.002672\n",
      "Train Epoch: 10 [23680/48000 (49%)]\tLoss: 0.008889\n",
      "Train Epoch: 10 [24320/48000 (51%)]\tLoss: 0.012956\n",
      "Train Epoch: 10 [24960/48000 (52%)]\tLoss: 0.003536\n",
      "Train Epoch: 10 [25600/48000 (53%)]\tLoss: 0.026909\n",
      "Train Epoch: 10 [26240/48000 (55%)]\tLoss: 0.006306\n",
      "Train Epoch: 10 [26880/48000 (56%)]\tLoss: 0.031603\n",
      "Train Epoch: 10 [27520/48000 (57%)]\tLoss: 0.013597\n",
      "Train Epoch: 10 [28160/48000 (59%)]\tLoss: 0.007218\n",
      "Train Epoch: 10 [28800/48000 (60%)]\tLoss: 0.041792\n",
      "Train Epoch: 10 [29440/48000 (61%)]\tLoss: 0.049704\n",
      "Train Epoch: 10 [30080/48000 (63%)]\tLoss: 0.005574\n",
      "Train Epoch: 10 [30720/48000 (64%)]\tLoss: 0.001516\n",
      "Train Epoch: 10 [31360/48000 (65%)]\tLoss: 0.039956\n",
      "Train Epoch: 10 [32000/48000 (67%)]\tLoss: 0.025277\n",
      "Train Epoch: 10 [32640/48000 (68%)]\tLoss: 0.002824\n",
      "Train Epoch: 10 [33280/48000 (69%)]\tLoss: 0.010667\n",
      "Train Epoch: 10 [33920/48000 (71%)]\tLoss: 0.048050\n",
      "Train Epoch: 10 [34560/48000 (72%)]\tLoss: 0.006978\n",
      "Train Epoch: 10 [35200/48000 (73%)]\tLoss: 0.012426\n",
      "Train Epoch: 10 [35840/48000 (75%)]\tLoss: 0.011851\n",
      "Train Epoch: 10 [36480/48000 (76%)]\tLoss: 0.076619\n",
      "Train Epoch: 10 [37120/48000 (77%)]\tLoss: 0.035927\n",
      "Train Epoch: 10 [37760/48000 (79%)]\tLoss: 0.009457\n",
      "Train Epoch: 10 [38400/48000 (80%)]\tLoss: 0.060280\n",
      "Train Epoch: 10 [39040/48000 (81%)]\tLoss: 0.035401\n",
      "Train Epoch: 10 [39680/48000 (83%)]\tLoss: 0.013314\n",
      "Train Epoch: 10 [40320/48000 (84%)]\tLoss: 0.011558\n",
      "Train Epoch: 10 [40960/48000 (85%)]\tLoss: 0.006174\n",
      "Train Epoch: 10 [41600/48000 (87%)]\tLoss: 0.012426\n",
      "Train Epoch: 10 [42240/48000 (88%)]\tLoss: 0.058091\n",
      "Train Epoch: 10 [42880/48000 (89%)]\tLoss: 0.003638\n",
      "Train Epoch: 10 [43520/48000 (91%)]\tLoss: 0.013803\n",
      "Train Epoch: 10 [44160/48000 (92%)]\tLoss: 0.001603\n",
      "Train Epoch: 10 [44800/48000 (93%)]\tLoss: 0.015776\n",
      "Train Epoch: 10 [45440/48000 (95%)]\tLoss: 0.000922\n",
      "Train Epoch: 10 [46080/48000 (96%)]\tLoss: 0.025573\n",
      "Train Epoch: 10 [46720/48000 (97%)]\tLoss: 0.003096\n",
      "Train Epoch: 10 [47360/48000 (99%)]\tLoss: 0.023068\n",
      "\n",
      "Test set: Average loss: 0.0439, Accuracy: 11840/12000 (99%)\n",
      "\n",
      "Train Epoch: 11 [0/48000 (0%)]\tLoss: 0.002742\n",
      "Train Epoch: 11 [640/48000 (1%)]\tLoss: 0.001533\n",
      "Train Epoch: 11 [1280/48000 (3%)]\tLoss: 0.002053\n",
      "Train Epoch: 11 [1920/48000 (4%)]\tLoss: 0.015767\n",
      "Train Epoch: 11 [2560/48000 (5%)]\tLoss: 0.010733\n",
      "Train Epoch: 11 [3200/48000 (7%)]\tLoss: 0.002432\n",
      "Train Epoch: 11 [3840/48000 (8%)]\tLoss: 0.014801\n",
      "Train Epoch: 11 [4480/48000 (9%)]\tLoss: 0.002042\n",
      "Train Epoch: 11 [5120/48000 (11%)]\tLoss: 0.034286\n",
      "Train Epoch: 11 [5760/48000 (12%)]\tLoss: 0.030046\n",
      "Train Epoch: 11 [6400/48000 (13%)]\tLoss: 0.052237\n",
      "Train Epoch: 11 [7040/48000 (15%)]\tLoss: 0.004382\n",
      "Train Epoch: 11 [7680/48000 (16%)]\tLoss: 0.007727\n",
      "Train Epoch: 11 [8320/48000 (17%)]\tLoss: 0.003595\n",
      "Train Epoch: 11 [8960/48000 (19%)]\tLoss: 0.006197\n",
      "Train Epoch: 11 [9600/48000 (20%)]\tLoss: 0.011116\n",
      "Train Epoch: 11 [10240/48000 (21%)]\tLoss: 0.008098\n",
      "Train Epoch: 11 [10880/48000 (23%)]\tLoss: 0.010239\n",
      "Train Epoch: 11 [11520/48000 (24%)]\tLoss: 0.012652\n",
      "Train Epoch: 11 [12160/48000 (25%)]\tLoss: 0.010211\n",
      "Train Epoch: 11 [12800/48000 (27%)]\tLoss: 0.010222\n",
      "Train Epoch: 11 [13440/48000 (28%)]\tLoss: 0.041043\n",
      "Train Epoch: 11 [14080/48000 (29%)]\tLoss: 0.077966\n",
      "Train Epoch: 11 [14720/48000 (31%)]\tLoss: 0.026824\n",
      "Train Epoch: 11 [15360/48000 (32%)]\tLoss: 0.024454\n",
      "Train Epoch: 11 [16000/48000 (33%)]\tLoss: 0.023002\n",
      "Train Epoch: 11 [16640/48000 (35%)]\tLoss: 0.011072\n",
      "Train Epoch: 11 [17280/48000 (36%)]\tLoss: 0.046342\n",
      "Train Epoch: 11 [17920/48000 (37%)]\tLoss: 0.000831\n",
      "Train Epoch: 11 [18560/48000 (39%)]\tLoss: 0.010071\n",
      "Train Epoch: 11 [19200/48000 (40%)]\tLoss: 0.003157\n",
      "Train Epoch: 11 [19840/48000 (41%)]\tLoss: 0.002910\n",
      "Train Epoch: 11 [20480/48000 (43%)]\tLoss: 0.019520\n",
      "Train Epoch: 11 [21120/48000 (44%)]\tLoss: 0.000165\n",
      "Train Epoch: 11 [21760/48000 (45%)]\tLoss: 0.029602\n",
      "Train Epoch: 11 [22400/48000 (47%)]\tLoss: 0.015623\n",
      "Train Epoch: 11 [23040/48000 (48%)]\tLoss: 0.019299\n",
      "Train Epoch: 11 [23680/48000 (49%)]\tLoss: 0.004769\n",
      "Train Epoch: 11 [24320/48000 (51%)]\tLoss: 0.005403\n",
      "Train Epoch: 11 [24960/48000 (52%)]\tLoss: 0.005370\n",
      "Train Epoch: 11 [25600/48000 (53%)]\tLoss: 0.011771\n",
      "Train Epoch: 11 [26240/48000 (55%)]\tLoss: 0.011095\n",
      "Train Epoch: 11 [26880/48000 (56%)]\tLoss: 0.012282\n",
      "Train Epoch: 11 [27520/48000 (57%)]\tLoss: 0.033527\n",
      "Train Epoch: 11 [28160/48000 (59%)]\tLoss: 0.055711\n",
      "Train Epoch: 11 [28800/48000 (60%)]\tLoss: 0.007445\n",
      "Train Epoch: 11 [29440/48000 (61%)]\tLoss: 0.024188\n",
      "Train Epoch: 11 [30080/48000 (63%)]\tLoss: 0.016140\n",
      "Train Epoch: 11 [30720/48000 (64%)]\tLoss: 0.002698\n",
      "Train Epoch: 11 [31360/48000 (65%)]\tLoss: 0.030570\n",
      "Train Epoch: 11 [32000/48000 (67%)]\tLoss: 0.003907\n",
      "Train Epoch: 11 [32640/48000 (68%)]\tLoss: 0.015843\n",
      "Train Epoch: 11 [33280/48000 (69%)]\tLoss: 0.001177\n",
      "Train Epoch: 11 [33920/48000 (71%)]\tLoss: 0.006621\n",
      "Train Epoch: 11 [34560/48000 (72%)]\tLoss: 0.003154\n",
      "Train Epoch: 11 [35200/48000 (73%)]\tLoss: 0.001019\n",
      "Train Epoch: 11 [35840/48000 (75%)]\tLoss: 0.003199\n",
      "Train Epoch: 11 [36480/48000 (76%)]\tLoss: 0.002351\n",
      "Train Epoch: 11 [37120/48000 (77%)]\tLoss: 0.043709\n",
      "Train Epoch: 11 [37760/48000 (79%)]\tLoss: 0.073887\n",
      "Train Epoch: 11 [38400/48000 (80%)]\tLoss: 0.009080\n",
      "Train Epoch: 11 [39040/48000 (81%)]\tLoss: 0.007618\n",
      "Train Epoch: 11 [39680/48000 (83%)]\tLoss: 0.062995\n",
      "Train Epoch: 11 [40320/48000 (84%)]\tLoss: 0.024658\n",
      "Train Epoch: 11 [40960/48000 (85%)]\tLoss: 0.015327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11 [41600/48000 (87%)]\tLoss: 0.005978\n",
      "Train Epoch: 11 [42240/48000 (88%)]\tLoss: 0.001344\n",
      "Train Epoch: 11 [42880/48000 (89%)]\tLoss: 0.058742\n",
      "Train Epoch: 11 [43520/48000 (91%)]\tLoss: 0.004424\n",
      "Train Epoch: 11 [44160/48000 (92%)]\tLoss: 0.019120\n",
      "Train Epoch: 11 [44800/48000 (93%)]\tLoss: 0.037471\n",
      "Train Epoch: 11 [45440/48000 (95%)]\tLoss: 0.004519\n",
      "Train Epoch: 11 [46080/48000 (96%)]\tLoss: 0.005845\n",
      "Train Epoch: 11 [46720/48000 (97%)]\tLoss: 0.004830\n",
      "Train Epoch: 11 [47360/48000 (99%)]\tLoss: 0.029914\n",
      "\n",
      "Test set: Average loss: 0.0429, Accuracy: 11851/12000 (99%)\n",
      "\n",
      "Train Epoch: 12 [0/48000 (0%)]\tLoss: 0.008647\n",
      "Train Epoch: 12 [640/48000 (1%)]\tLoss: 0.003400\n",
      "Train Epoch: 12 [1280/48000 (3%)]\tLoss: 0.014665\n",
      "Train Epoch: 12 [1920/48000 (4%)]\tLoss: 0.014888\n",
      "Train Epoch: 12 [2560/48000 (5%)]\tLoss: 0.000880\n",
      "Train Epoch: 12 [3200/48000 (7%)]\tLoss: 0.004970\n",
      "Train Epoch: 12 [3840/48000 (8%)]\tLoss: 0.036876\n",
      "Train Epoch: 12 [4480/48000 (9%)]\tLoss: 0.030630\n",
      "Train Epoch: 12 [5120/48000 (11%)]\tLoss: 0.077405\n",
      "Train Epoch: 12 [5760/48000 (12%)]\tLoss: 0.014296\n",
      "Train Epoch: 12 [6400/48000 (13%)]\tLoss: 0.004167\n",
      "Train Epoch: 12 [7040/48000 (15%)]\tLoss: 0.016179\n",
      "Train Epoch: 12 [7680/48000 (16%)]\tLoss: 0.038666\n",
      "Train Epoch: 12 [8320/48000 (17%)]\tLoss: 0.000845\n",
      "Train Epoch: 12 [8960/48000 (19%)]\tLoss: 0.023121\n",
      "Train Epoch: 12 [9600/48000 (20%)]\tLoss: 0.004546\n",
      "Train Epoch: 12 [10240/48000 (21%)]\tLoss: 0.004272\n",
      "Train Epoch: 12 [10880/48000 (23%)]\tLoss: 0.006328\n",
      "Train Epoch: 12 [11520/48000 (24%)]\tLoss: 0.008299\n",
      "Train Epoch: 12 [12160/48000 (25%)]\tLoss: 0.005803\n",
      "Train Epoch: 12 [12800/48000 (27%)]\tLoss: 0.011527\n",
      "Train Epoch: 12 [13440/48000 (28%)]\tLoss: 0.005253\n",
      "Train Epoch: 12 [14080/48000 (29%)]\tLoss: 0.005444\n",
      "Train Epoch: 12 [14720/48000 (31%)]\tLoss: 0.003381\n",
      "Train Epoch: 12 [15360/48000 (32%)]\tLoss: 0.018106\n",
      "Train Epoch: 12 [16000/48000 (33%)]\tLoss: 0.006931\n",
      "Train Epoch: 12 [16640/48000 (35%)]\tLoss: 0.004356\n",
      "Train Epoch: 12 [17280/48000 (36%)]\tLoss: 0.005151\n",
      "Train Epoch: 12 [17920/48000 (37%)]\tLoss: 0.010464\n",
      "Train Epoch: 12 [18560/48000 (39%)]\tLoss: 0.007882\n",
      "Train Epoch: 12 [19200/48000 (40%)]\tLoss: 0.003721\n",
      "Train Epoch: 12 [19840/48000 (41%)]\tLoss: 0.005276\n",
      "Train Epoch: 12 [20480/48000 (43%)]\tLoss: 0.017922\n",
      "Train Epoch: 12 [21120/48000 (44%)]\tLoss: 0.011179\n",
      "Train Epoch: 12 [21760/48000 (45%)]\tLoss: 0.020145\n",
      "Train Epoch: 12 [22400/48000 (47%)]\tLoss: 0.008884\n",
      "Train Epoch: 12 [23040/48000 (48%)]\tLoss: 0.027606\n",
      "Train Epoch: 12 [23680/48000 (49%)]\tLoss: 0.021635\n",
      "Train Epoch: 12 [24320/48000 (51%)]\tLoss: 0.010932\n",
      "Train Epoch: 12 [24960/48000 (52%)]\tLoss: 0.003356\n",
      "Train Epoch: 12 [25600/48000 (53%)]\tLoss: 0.054883\n",
      "Train Epoch: 12 [26240/48000 (55%)]\tLoss: 0.004432\n",
      "Train Epoch: 12 [26880/48000 (56%)]\tLoss: 0.002958\n",
      "Train Epoch: 12 [27520/48000 (57%)]\tLoss: 0.003204\n",
      "Train Epoch: 12 [28160/48000 (59%)]\tLoss: 0.022620\n",
      "Train Epoch: 12 [28800/48000 (60%)]\tLoss: 0.008738\n",
      "Train Epoch: 12 [29440/48000 (61%)]\tLoss: 0.003020\n",
      "Train Epoch: 12 [30080/48000 (63%)]\tLoss: 0.016111\n",
      "Train Epoch: 12 [30720/48000 (64%)]\tLoss: 0.017738\n",
      "Train Epoch: 12 [31360/48000 (65%)]\tLoss: 0.018098\n",
      "Train Epoch: 12 [32000/48000 (67%)]\tLoss: 0.004243\n",
      "Train Epoch: 12 [32640/48000 (68%)]\tLoss: 0.006019\n",
      "Train Epoch: 12 [33280/48000 (69%)]\tLoss: 0.010861\n",
      "Train Epoch: 12 [33920/48000 (71%)]\tLoss: 0.004800\n",
      "Train Epoch: 12 [34560/48000 (72%)]\tLoss: 0.048445\n",
      "Train Epoch: 12 [35200/48000 (73%)]\tLoss: 0.023400\n",
      "Train Epoch: 12 [35840/48000 (75%)]\tLoss: 0.012763\n",
      "Train Epoch: 12 [36480/48000 (76%)]\tLoss: 0.001163\n",
      "Train Epoch: 12 [37120/48000 (77%)]\tLoss: 0.004246\n",
      "Train Epoch: 12 [37760/48000 (79%)]\tLoss: 0.007502\n",
      "Train Epoch: 12 [38400/48000 (80%)]\tLoss: 0.003824\n",
      "Train Epoch: 12 [39040/48000 (81%)]\tLoss: 0.021665\n",
      "Train Epoch: 12 [39680/48000 (83%)]\tLoss: 0.001316\n",
      "Train Epoch: 12 [40320/48000 (84%)]\tLoss: 0.001130\n",
      "Train Epoch: 12 [40960/48000 (85%)]\tLoss: 0.004109\n",
      "Train Epoch: 12 [41600/48000 (87%)]\tLoss: 0.002996\n",
      "Train Epoch: 12 [42240/48000 (88%)]\tLoss: 0.003166\n",
      "Train Epoch: 12 [42880/48000 (89%)]\tLoss: 0.004835\n",
      "Train Epoch: 12 [43520/48000 (91%)]\tLoss: 0.006263\n",
      "Train Epoch: 12 [44160/48000 (92%)]\tLoss: 0.001383\n",
      "Train Epoch: 12 [44800/48000 (93%)]\tLoss: 0.006029\n",
      "Train Epoch: 12 [45440/48000 (95%)]\tLoss: 0.002839\n",
      "Train Epoch: 12 [46080/48000 (96%)]\tLoss: 0.050776\n",
      "Train Epoch: 12 [46720/48000 (97%)]\tLoss: 0.000793\n",
      "Train Epoch: 12 [47360/48000 (99%)]\tLoss: 0.000403\n",
      "\n",
      "Test set: Average loss: 0.0365, Accuracy: 11860/12000 (99%)\n",
      "\n",
      "Train Epoch: 13 [0/48000 (0%)]\tLoss: 0.000284\n",
      "Train Epoch: 13 [640/48000 (1%)]\tLoss: 0.004368\n",
      "Train Epoch: 13 [1280/48000 (3%)]\tLoss: 0.011687\n",
      "Train Epoch: 13 [1920/48000 (4%)]\tLoss: 0.007695\n",
      "Train Epoch: 13 [2560/48000 (5%)]\tLoss: 0.047780\n",
      "Train Epoch: 13 [3200/48000 (7%)]\tLoss: 0.006212\n",
      "Train Epoch: 13 [3840/48000 (8%)]\tLoss: 0.089319\n",
      "Train Epoch: 13 [4480/48000 (9%)]\tLoss: 0.017011\n",
      "Train Epoch: 13 [5120/48000 (11%)]\tLoss: 0.011077\n",
      "Train Epoch: 13 [5760/48000 (12%)]\tLoss: 0.032246\n",
      "Train Epoch: 13 [6400/48000 (13%)]\tLoss: 0.002302\n",
      "Train Epoch: 13 [7040/48000 (15%)]\tLoss: 0.022976\n",
      "Train Epoch: 13 [7680/48000 (16%)]\tLoss: 0.002104\n",
      "Train Epoch: 13 [8320/48000 (17%)]\tLoss: 0.026514\n",
      "Train Epoch: 13 [8960/48000 (19%)]\tLoss: 0.003290\n",
      "Train Epoch: 13 [9600/48000 (20%)]\tLoss: 0.003566\n",
      "Train Epoch: 13 [10240/48000 (21%)]\tLoss: 0.007111\n",
      "Train Epoch: 13 [10880/48000 (23%)]\tLoss: 0.043867\n",
      "Train Epoch: 13 [11520/48000 (24%)]\tLoss: 0.005940\n",
      "Train Epoch: 13 [12160/48000 (25%)]\tLoss: 0.004430\n",
      "Train Epoch: 13 [12800/48000 (27%)]\tLoss: 0.000328\n",
      "Train Epoch: 13 [13440/48000 (28%)]\tLoss: 0.010050\n",
      "Train Epoch: 13 [14080/48000 (29%)]\tLoss: 0.035763\n",
      "Train Epoch: 13 [14720/48000 (31%)]\tLoss: 0.004859\n",
      "Train Epoch: 13 [15360/48000 (32%)]\tLoss: 0.001396\n",
      "Train Epoch: 13 [16000/48000 (33%)]\tLoss: 0.034997\n",
      "Train Epoch: 13 [16640/48000 (35%)]\tLoss: 0.004319\n",
      "Train Epoch: 13 [17280/48000 (36%)]\tLoss: 0.036203\n",
      "Train Epoch: 13 [17920/48000 (37%)]\tLoss: 0.003826\n",
      "Train Epoch: 13 [18560/48000 (39%)]\tLoss: 0.011537\n",
      "Train Epoch: 13 [19200/48000 (40%)]\tLoss: 0.030864\n",
      "Train Epoch: 13 [19840/48000 (41%)]\tLoss: 0.030985\n",
      "Train Epoch: 13 [20480/48000 (43%)]\tLoss: 0.006108\n",
      "Train Epoch: 13 [21120/48000 (44%)]\tLoss: 0.001852\n",
      "Train Epoch: 13 [21760/48000 (45%)]\tLoss: 0.010854\n",
      "Train Epoch: 13 [22400/48000 (47%)]\tLoss: 0.010058\n",
      "Train Epoch: 13 [23040/48000 (48%)]\tLoss: 0.017955\n",
      "Train Epoch: 13 [23680/48000 (49%)]\tLoss: 0.000509\n",
      "Train Epoch: 13 [24320/48000 (51%)]\tLoss: 0.008811\n",
      "Train Epoch: 13 [24960/48000 (52%)]\tLoss: 0.057141\n",
      "Train Epoch: 13 [25600/48000 (53%)]\tLoss: 0.018298\n",
      "Train Epoch: 13 [26240/48000 (55%)]\tLoss: 0.013282\n",
      "Train Epoch: 13 [26880/48000 (56%)]\tLoss: 0.004471\n",
      "Train Epoch: 13 [27520/48000 (57%)]\tLoss: 0.001450\n",
      "Train Epoch: 13 [28160/48000 (59%)]\tLoss: 0.002324\n",
      "Train Epoch: 13 [28800/48000 (60%)]\tLoss: 0.008440\n",
      "Train Epoch: 13 [29440/48000 (61%)]\tLoss: 0.021407\n",
      "Train Epoch: 13 [30080/48000 (63%)]\tLoss: 0.011928\n",
      "Train Epoch: 13 [30720/48000 (64%)]\tLoss: 0.001929\n",
      "Train Epoch: 13 [31360/48000 (65%)]\tLoss: 0.007000\n",
      "Train Epoch: 13 [32000/48000 (67%)]\tLoss: 0.004795\n",
      "Train Epoch: 13 [32640/48000 (68%)]\tLoss: 0.045665\n",
      "Train Epoch: 13 [33280/48000 (69%)]\tLoss: 0.000903\n",
      "Train Epoch: 13 [33920/48000 (71%)]\tLoss: 0.026476\n",
      "Train Epoch: 13 [34560/48000 (72%)]\tLoss: 0.027801\n",
      "Train Epoch: 13 [35200/48000 (73%)]\tLoss: 0.001424\n",
      "Train Epoch: 13 [35840/48000 (75%)]\tLoss: 0.010694\n",
      "Train Epoch: 13 [36480/48000 (76%)]\tLoss: 0.002223\n",
      "Train Epoch: 13 [37120/48000 (77%)]\tLoss: 0.001669\n",
      "Train Epoch: 13 [37760/48000 (79%)]\tLoss: 0.000822\n",
      "Train Epoch: 13 [38400/48000 (80%)]\tLoss: 0.024322\n",
      "Train Epoch: 13 [39040/48000 (81%)]\tLoss: 0.016665\n",
      "Train Epoch: 13 [39680/48000 (83%)]\tLoss: 0.023174\n",
      "Train Epoch: 13 [40320/48000 (84%)]\tLoss: 0.009928\n",
      "Train Epoch: 13 [40960/48000 (85%)]\tLoss: 0.027513\n",
      "Train Epoch: 13 [41600/48000 (87%)]\tLoss: 0.009711\n",
      "Train Epoch: 13 [42240/48000 (88%)]\tLoss: 0.017129\n",
      "Train Epoch: 13 [42880/48000 (89%)]\tLoss: 0.018933\n",
      "Train Epoch: 13 [43520/48000 (91%)]\tLoss: 0.017541\n",
      "Train Epoch: 13 [44160/48000 (92%)]\tLoss: 0.048181\n",
      "Train Epoch: 13 [44800/48000 (93%)]\tLoss: 0.014352\n",
      "Train Epoch: 13 [45440/48000 (95%)]\tLoss: 0.001255\n",
      "Train Epoch: 13 [46080/48000 (96%)]\tLoss: 0.046407\n",
      "Train Epoch: 13 [46720/48000 (97%)]\tLoss: 0.012580\n",
      "Train Epoch: 13 [47360/48000 (99%)]\tLoss: 0.014860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0362, Accuracy: 11873/12000 (99%)\n",
      "\n",
      "Train Epoch: 14 [0/48000 (0%)]\tLoss: 0.000455\n",
      "Train Epoch: 14 [640/48000 (1%)]\tLoss: 0.000457\n",
      "Train Epoch: 14 [1280/48000 (3%)]\tLoss: 0.005247\n",
      "Train Epoch: 14 [1920/48000 (4%)]\tLoss: 0.001571\n",
      "Train Epoch: 14 [2560/48000 (5%)]\tLoss: 0.030644\n",
      "Train Epoch: 14 [3200/48000 (7%)]\tLoss: 0.003971\n",
      "Train Epoch: 14 [3840/48000 (8%)]\tLoss: 0.009792\n",
      "Train Epoch: 14 [4480/48000 (9%)]\tLoss: 0.004800\n",
      "Train Epoch: 14 [5120/48000 (11%)]\tLoss: 0.000516\n",
      "Train Epoch: 14 [5760/48000 (12%)]\tLoss: 0.001645\n",
      "Train Epoch: 14 [6400/48000 (13%)]\tLoss: 0.006928\n",
      "Train Epoch: 14 [7040/48000 (15%)]\tLoss: 0.001180\n",
      "Train Epoch: 14 [7680/48000 (16%)]\tLoss: 0.073001\n",
      "Train Epoch: 14 [8320/48000 (17%)]\tLoss: 0.000960\n",
      "Train Epoch: 14 [8960/48000 (19%)]\tLoss: 0.003821\n",
      "Train Epoch: 14 [9600/48000 (20%)]\tLoss: 0.001420\n",
      "Train Epoch: 14 [10240/48000 (21%)]\tLoss: 0.002640\n",
      "Train Epoch: 14 [10880/48000 (23%)]\tLoss: 0.002630\n",
      "Train Epoch: 14 [11520/48000 (24%)]\tLoss: 0.091377\n",
      "Train Epoch: 14 [12160/48000 (25%)]\tLoss: 0.004962\n",
      "Train Epoch: 14 [12800/48000 (27%)]\tLoss: 0.008436\n",
      "Train Epoch: 14 [13440/48000 (28%)]\tLoss: 0.005885\n",
      "Train Epoch: 14 [14080/48000 (29%)]\tLoss: 0.001139\n",
      "Train Epoch: 14 [14720/48000 (31%)]\tLoss: 0.059780\n",
      "Train Epoch: 14 [15360/48000 (32%)]\tLoss: 0.007000\n",
      "Train Epoch: 14 [16000/48000 (33%)]\tLoss: 0.007269\n",
      "Train Epoch: 14 [16640/48000 (35%)]\tLoss: 0.013661\n",
      "Train Epoch: 14 [17280/48000 (36%)]\tLoss: 0.002269\n",
      "Train Epoch: 14 [17920/48000 (37%)]\tLoss: 0.037539\n",
      "Train Epoch: 14 [18560/48000 (39%)]\tLoss: 0.009709\n",
      "Train Epoch: 14 [19200/48000 (40%)]\tLoss: 0.001442\n",
      "Train Epoch: 14 [19840/48000 (41%)]\tLoss: 0.001825\n",
      "Train Epoch: 14 [20480/48000 (43%)]\tLoss: 0.025536\n",
      "Train Epoch: 14 [21120/48000 (44%)]\tLoss: 0.018681\n",
      "Train Epoch: 14 [21760/48000 (45%)]\tLoss: 0.009461\n",
      "Train Epoch: 14 [22400/48000 (47%)]\tLoss: 0.018260\n",
      "Train Epoch: 14 [23040/48000 (48%)]\tLoss: 0.004137\n",
      "Train Epoch: 14 [23680/48000 (49%)]\tLoss: 0.002935\n",
      "Train Epoch: 14 [24320/48000 (51%)]\tLoss: 0.002078\n",
      "Train Epoch: 14 [24960/48000 (52%)]\tLoss: 0.020139\n",
      "Train Epoch: 14 [25600/48000 (53%)]\tLoss: 0.016345\n",
      "Train Epoch: 14 [26240/48000 (55%)]\tLoss: 0.000945\n",
      "Train Epoch: 14 [26880/48000 (56%)]\tLoss: 0.095549\n",
      "Train Epoch: 14 [27520/48000 (57%)]\tLoss: 0.000853\n",
      "Train Epoch: 14 [28160/48000 (59%)]\tLoss: 0.001321\n",
      "Train Epoch: 14 [28800/48000 (60%)]\tLoss: 0.005559\n",
      "Train Epoch: 14 [29440/48000 (61%)]\tLoss: 0.003837\n",
      "Train Epoch: 14 [30080/48000 (63%)]\tLoss: 0.035573\n",
      "Train Epoch: 14 [30720/48000 (64%)]\tLoss: 0.029329\n",
      "Train Epoch: 14 [31360/48000 (65%)]\tLoss: 0.011027\n",
      "Train Epoch: 14 [32000/48000 (67%)]\tLoss: 0.001430\n",
      "Train Epoch: 14 [32640/48000 (68%)]\tLoss: 0.028797\n",
      "Train Epoch: 14 [33280/48000 (69%)]\tLoss: 0.005298\n",
      "Train Epoch: 14 [33920/48000 (71%)]\tLoss: 0.006961\n",
      "Train Epoch: 14 [34560/48000 (72%)]\tLoss: 0.011779\n",
      "Train Epoch: 14 [35200/48000 (73%)]\tLoss: 0.003774\n",
      "Train Epoch: 14 [35840/48000 (75%)]\tLoss: 0.000869\n",
      "Train Epoch: 14 [36480/48000 (76%)]\tLoss: 0.003264\n",
      "Train Epoch: 14 [37120/48000 (77%)]\tLoss: 0.008052\n",
      "Train Epoch: 14 [37760/48000 (79%)]\tLoss: 0.006280\n",
      "Train Epoch: 14 [38400/48000 (80%)]\tLoss: 0.072284\n",
      "Train Epoch: 14 [39040/48000 (81%)]\tLoss: 0.222915\n",
      "Train Epoch: 14 [39680/48000 (83%)]\tLoss: 0.001663\n",
      "Train Epoch: 14 [40320/48000 (84%)]\tLoss: 0.003015\n",
      "Train Epoch: 14 [40960/48000 (85%)]\tLoss: 0.000372\n",
      "Train Epoch: 14 [41600/48000 (87%)]\tLoss: 0.001354\n",
      "Train Epoch: 14 [42240/48000 (88%)]\tLoss: 0.002380\n",
      "Train Epoch: 14 [42880/48000 (89%)]\tLoss: 0.023332\n",
      "Train Epoch: 14 [43520/48000 (91%)]\tLoss: 0.002432\n",
      "Train Epoch: 14 [44160/48000 (92%)]\tLoss: 0.003002\n",
      "Train Epoch: 14 [44800/48000 (93%)]\tLoss: 0.003743\n",
      "Train Epoch: 14 [45440/48000 (95%)]\tLoss: 0.001795\n",
      "Train Epoch: 14 [46080/48000 (96%)]\tLoss: 0.003074\n",
      "Train Epoch: 14 [46720/48000 (97%)]\tLoss: 0.001406\n",
      "Train Epoch: 14 [47360/48000 (99%)]\tLoss: 0.000858\n",
      "\n",
      "Test set: Average loss: 0.0376, Accuracy: 11864/12000 (99%)\n",
      "\n",
      "Train Epoch: 15 [0/48000 (0%)]\tLoss: 0.010659\n",
      "Train Epoch: 15 [640/48000 (1%)]\tLoss: 0.000833\n",
      "Train Epoch: 15 [1280/48000 (3%)]\tLoss: 0.149330\n",
      "Train Epoch: 15 [1920/48000 (4%)]\tLoss: 0.021562\n",
      "Train Epoch: 15 [2560/48000 (5%)]\tLoss: 0.002666\n",
      "Train Epoch: 15 [3200/48000 (7%)]\tLoss: 0.022720\n",
      "Train Epoch: 15 [3840/48000 (8%)]\tLoss: 0.004265\n",
      "Train Epoch: 15 [4480/48000 (9%)]\tLoss: 0.001759\n",
      "Train Epoch: 15 [5120/48000 (11%)]\tLoss: 0.003748\n",
      "Train Epoch: 15 [5760/48000 (12%)]\tLoss: 0.006943\n",
      "Train Epoch: 15 [6400/48000 (13%)]\tLoss: 0.002225\n",
      "Train Epoch: 15 [7040/48000 (15%)]\tLoss: 0.001136\n",
      "Train Epoch: 15 [7680/48000 (16%)]\tLoss: 0.002269\n",
      "Train Epoch: 15 [8320/48000 (17%)]\tLoss: 0.033498\n",
      "Train Epoch: 15 [8960/48000 (19%)]\tLoss: 0.010817\n",
      "Train Epoch: 15 [9600/48000 (20%)]\tLoss: 0.001748\n",
      "Train Epoch: 15 [10240/48000 (21%)]\tLoss: 0.004969\n",
      "Train Epoch: 15 [10880/48000 (23%)]\tLoss: 0.005091\n",
      "Train Epoch: 15 [11520/48000 (24%)]\tLoss: 0.002163\n",
      "Train Epoch: 15 [12160/48000 (25%)]\tLoss: 0.001634\n",
      "Train Epoch: 15 [12800/48000 (27%)]\tLoss: 0.014287\n",
      "Train Epoch: 15 [13440/48000 (28%)]\tLoss: 0.008144\n",
      "Train Epoch: 15 [14080/48000 (29%)]\tLoss: 0.000964\n",
      "Train Epoch: 15 [14720/48000 (31%)]\tLoss: 0.047728\n",
      "Train Epoch: 15 [15360/48000 (32%)]\tLoss: 0.027628\n",
      "Train Epoch: 15 [16000/48000 (33%)]\tLoss: 0.002883\n",
      "Train Epoch: 15 [16640/48000 (35%)]\tLoss: 0.005300\n",
      "Train Epoch: 15 [17280/48000 (36%)]\tLoss: 0.010242\n",
      "Train Epoch: 15 [17920/48000 (37%)]\tLoss: 0.010908\n",
      "Train Epoch: 15 [18560/48000 (39%)]\tLoss: 0.004742\n",
      "Train Epoch: 15 [19200/48000 (40%)]\tLoss: 0.000856\n",
      "Train Epoch: 15 [19840/48000 (41%)]\tLoss: 0.011367\n",
      "Train Epoch: 15 [20480/48000 (43%)]\tLoss: 0.001398\n",
      "Train Epoch: 15 [21120/48000 (44%)]\tLoss: 0.004033\n",
      "Train Epoch: 15 [21760/48000 (45%)]\tLoss: 0.007897\n",
      "Train Epoch: 15 [22400/48000 (47%)]\tLoss: 0.008228\n",
      "Train Epoch: 15 [23040/48000 (48%)]\tLoss: 0.007889\n",
      "Train Epoch: 15 [23680/48000 (49%)]\tLoss: 0.002608\n",
      "Train Epoch: 15 [24320/48000 (51%)]\tLoss: 0.009295\n",
      "Train Epoch: 15 [24960/48000 (52%)]\tLoss: 0.000388\n",
      "Train Epoch: 15 [25600/48000 (53%)]\tLoss: 0.008790\n",
      "Train Epoch: 15 [26240/48000 (55%)]\tLoss: 0.002514\n",
      "Train Epoch: 15 [26880/48000 (56%)]\tLoss: 0.006276\n",
      "Train Epoch: 15 [27520/48000 (57%)]\tLoss: 0.032735\n",
      "Train Epoch: 15 [28160/48000 (59%)]\tLoss: 0.007692\n",
      "Train Epoch: 15 [28800/48000 (60%)]\tLoss: 0.009997\n",
      "Train Epoch: 15 [29440/48000 (61%)]\tLoss: 0.003096\n",
      "Train Epoch: 15 [30080/48000 (63%)]\tLoss: 0.014291\n",
      "Train Epoch: 15 [30720/48000 (64%)]\tLoss: 0.002995\n",
      "Train Epoch: 15 [31360/48000 (65%)]\tLoss: 0.019761\n",
      "Train Epoch: 15 [32000/48000 (67%)]\tLoss: 0.106504\n",
      "Train Epoch: 15 [32640/48000 (68%)]\tLoss: 0.010029\n",
      "Train Epoch: 15 [33280/48000 (69%)]\tLoss: 0.013803\n",
      "Train Epoch: 15 [33920/48000 (71%)]\tLoss: 0.011101\n",
      "Train Epoch: 15 [34560/48000 (72%)]\tLoss: 0.013398\n",
      "Train Epoch: 15 [35200/48000 (73%)]\tLoss: 0.000402\n",
      "Train Epoch: 15 [35840/48000 (75%)]\tLoss: 0.004484\n",
      "Train Epoch: 15 [36480/48000 (76%)]\tLoss: 0.001539\n",
      "Train Epoch: 15 [37120/48000 (77%)]\tLoss: 0.003905\n",
      "Train Epoch: 15 [37760/48000 (79%)]\tLoss: 0.011109\n",
      "Train Epoch: 15 [38400/48000 (80%)]\tLoss: 0.001607\n",
      "Train Epoch: 15 [39040/48000 (81%)]\tLoss: 0.005520\n",
      "Train Epoch: 15 [39680/48000 (83%)]\tLoss: 0.001583\n",
      "Train Epoch: 15 [40320/48000 (84%)]\tLoss: 0.000270\n",
      "Train Epoch: 15 [40960/48000 (85%)]\tLoss: 0.010415\n",
      "Train Epoch: 15 [41600/48000 (87%)]\tLoss: 0.001450\n",
      "Train Epoch: 15 [42240/48000 (88%)]\tLoss: 0.001836\n",
      "Train Epoch: 15 [42880/48000 (89%)]\tLoss: 0.003940\n",
      "Train Epoch: 15 [43520/48000 (91%)]\tLoss: 0.002839\n",
      "Train Epoch: 15 [44160/48000 (92%)]\tLoss: 0.003404\n",
      "Train Epoch: 15 [44800/48000 (93%)]\tLoss: 0.007081\n",
      "Train Epoch: 15 [45440/48000 (95%)]\tLoss: 0.048704\n",
      "Train Epoch: 15 [46080/48000 (96%)]\tLoss: 0.002862\n",
      "Train Epoch: 15 [46720/48000 (97%)]\tLoss: 0.003867\n",
      "Train Epoch: 15 [47360/48000 (99%)]\tLoss: 0.009506\n",
      "\n",
      "Test set: Average loss: 0.0358, Accuracy: 11873/12000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "\n",
    "epochs = 15\n",
    "log_interval = 10\n",
    "\n",
    "list_accuracy = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch, log_interval)\n",
    "    accuracy = test(model, device, test_loader)\n",
    "    list_accuracy.append(accuracy)\n",
    "\n",
    "# save model\n",
    "torch.save(model.state_dict(),\"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## étape 4 : évolution de l'accuracy au cour des epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(1,len(list_accuracy)+1), list_accuracy, 'k')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.axis([0.9,len(list_accuracy)+0.1,90,100]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
